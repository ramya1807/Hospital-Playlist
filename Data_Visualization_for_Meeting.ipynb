{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Visualization for Meeting.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN9PnkcJP7V3PMof/Drc4Lb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramya1807/Hospital-Playlist/blob/main/Data_Visualization_for_Meeting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCT03c_3xRnx"
      },
      "source": [
        "#Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9BarvCMxQ2g"
      },
      "source": [
        "#Model Naive Baiyes for predicting trauma or indiv mental health indicators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19B8RrifxhQg"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('data_cleaned2.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_7Zc3TrshiO",
        "outputId": "389096fc-b5ae-40b6-eed3-38416bbe9e3e"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['gender', 'age', 'amount_music', 'life_enjoyment', 'resilience',\n",
              "       'balanced_life', 'emotional_flex', 'self_actualization', 'trauma',\n",
              "       'total_health', 'health_categorical', 'energy', 'dance', 'liveness',\n",
              "       'valence', 'tempo', 'instrumental', 'acoustic', 'popularity', 'genres'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp-pvLgjt_t6"
      },
      "source": [
        "##trauma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_JyjRmosoAI"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBxWBtchtJ8m"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def evaluate_on_training_set(y_test, y_pred):\n",
        "  # Calculate AUC\n",
        "  #print(\"AUC is: \", roc_auc_score(y_test, y_pred))\n",
        "  \n",
        "  # print out recall and precision\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  \n",
        "  # print out confusion matrix\n",
        "  print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqYGh-E3tmeV"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB() # Define the model with parameters"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4J51Ai4tuch",
        "outputId": "280d752c-34e3-4949-e17f-0051d683c7b0"
      },
      "source": [
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.10      0.09      0.10        11\n",
            "           2       0.05      0.04      0.04        28\n",
            "           3       0.30      0.31      0.31        48\n",
            "           4       0.23      0.47      0.31        36\n",
            "           5       0.00      0.00      0.00        26\n",
            "           6       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.20       166\n",
            "   macro avg       0.10      0.13      0.11       166\n",
            "weighted avg       0.15      0.20      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  4  0  0]\n",
            " [ 0  1  0  4  6  0  0]\n",
            " [ 0  2  1 10 12  2  1]\n",
            " [ 0  3  8 15 20  1  1]\n",
            " [ 1  0  9  6 17  2  1]\n",
            " [ 0  2  1 12 11  0  0]\n",
            " [ 1  2  1  3  5  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVdCdOknuQU_"
      },
      "source": [
        "##life enjoyment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf1c_tz3uPqa"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0gOvlFxvR1M",
        "outputId": "6333227e-bbdf-48a8-df36-3fe984fad798"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB() # Define the model with parameters\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.10      0.09      0.10        11\n",
            "           2       0.05      0.04      0.04        28\n",
            "           3       0.30      0.31      0.31        48\n",
            "           4       0.23      0.47      0.31        36\n",
            "           5       0.00      0.00      0.00        26\n",
            "           6       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.20       166\n",
            "   macro avg       0.10      0.13      0.11       166\n",
            "weighted avg       0.15      0.20      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  4  0  0]\n",
            " [ 0  1  0  4  6  0  0]\n",
            " [ 0  2  1 10 12  2  1]\n",
            " [ 0  3  8 15 20  1  1]\n",
            " [ 1  0  9  6 17  2  1]\n",
            " [ 0  2  1 12 11  0  0]\n",
            " [ 1  2  1  3  5  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj-onViEuucA"
      },
      "source": [
        "##resilience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL4NYqXzwPdZ"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_SIcAtUwYgj",
        "outputId": "a8d5ee60-9418-4eef-f18f-43f931dc9a9c"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB() # Define the model with parameters\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.00      0.00      0.00        18\n",
            "           3       0.08      0.04      0.06        23\n",
            "           4       0.30      0.68      0.42        47\n",
            "           5       0.32      0.18      0.23        49\n",
            "           6       0.00      0.00      0.00        26\n",
            "\n",
            "    accuracy                           0.25       166\n",
            "   macro avg       0.10      0.13      0.10       166\n",
            "weighted avg       0.19      0.25      0.19       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  2  0  0]\n",
            " [ 0  0  0  2 13  3  0]\n",
            " [ 1  0  4  1 10  7  0]\n",
            " [ 0  0  5  2 32  8  0]\n",
            " [ 2  2  3  5 28  9  0]\n",
            " [ 0  0  1  2 22  1  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBm8cm5BuyZ9"
      },
      "source": [
        "##balanced life"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cr3GmHHwfhy"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRM65-iowoAA",
        "outputId": "d47fe33e-013c-4f87-81c6-3bc655104feb"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB() # Define the model with parameters\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.33      0.11      0.17        36\n",
            "           3       0.10      0.06      0.07        36\n",
            "           4       0.23      0.28      0.25        32\n",
            "           5       0.23      0.50      0.32        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.20       166\n",
            "   macro avg       0.13      0.14      0.12       166\n",
            "weighted avg       0.19      0.20      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  1  0  0]\n",
            " [ 0  0  0  4  1  1  0]\n",
            " [ 2  2  4  2 11 15  0]\n",
            " [ 0  2  4  2  6 21  1]\n",
            " [ 0  2  1  4  9 15  1]\n",
            " [ 1  0  2  7  9 19  0]\n",
            " [ 0  2  0  1  3 10  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtQrmihBu4E5"
      },
      "source": [
        "##emotional flexibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw25-SZGwotE"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl8iM4k2wpC6",
        "outputId": "bc0a48e2-42ea-460d-d842-bc7c978000b8"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB() # Define the model with parameters\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.05      0.27      0.08        11\n",
            "           2       0.22      0.07      0.11        28\n",
            "           3       0.16      0.25      0.20        24\n",
            "           4       0.17      0.11      0.13        38\n",
            "           5       0.15      0.11      0.13        36\n",
            "           6       0.50      0.12      0.20        24\n",
            "\n",
            "    accuracy                           0.13       166\n",
            "   macro avg       0.18      0.13      0.12       166\n",
            "weighted avg       0.21      0.13      0.14       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  1  0  2  1  1  0]\n",
            " [ 0  3  2  2  2  2  0]\n",
            " [ 0  8  2  3  5  8  2]\n",
            " [ 0 10  2  6  4  2  0]\n",
            " [ 0 14  0 13  4  7  0]\n",
            " [ 1 16  2  8  4  4  1]\n",
            " [ 0 11  1  3  3  3  3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ix5fSOFu8lW"
      },
      "source": [
        "##self-actualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUB0MjE3wqIw"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AHoW5rCwqYe",
        "outputId": "59e3ff28-ae7e-4aea-a40f-76d35680aaec"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB() # Define the model with parameters\n",
        "\n",
        "model.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.08      0.92      0.15        12\n",
            "           3       0.00      0.00      0.00        20\n",
            "           4       0.00      0.00      0.00        39\n",
            "           5       0.17      0.02      0.04        47\n",
            "           6       0.20      0.03      0.05        38\n",
            "\n",
            "    accuracy                           0.08       166\n",
            "   macro avg       0.06      0.14      0.03       166\n",
            "weighted avg       0.10      0.08      0.03       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  3  0  0  0  0]\n",
            " [ 0  0  6  0  0  1  0]\n",
            " [ 0  0 11  0  1  0  0]\n",
            " [ 0  1 17  0  1  1  0]\n",
            " [ 1  4 30  0  0  1  3]\n",
            " [ 0  3 37  0  5  1  1]\n",
            " [ 0  0 30  0  5  2  1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCrLXKuLxYo8"
      },
      "source": [
        "#Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfEpMf0lxeJZ"
      },
      "source": [
        "#Regression - for predicting total health score or individual mental health indicators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "634viRoJyC6-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I25S2gU0ZdK"
      },
      "source": [
        "##total health"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX01fdIVyEWo",
        "outputId": "84aa1c87-28f9-42c3-9738-517865ca31e0"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['total_health', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'trauma',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.630289967550237"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB7t9mNp0cKm"
      },
      "source": [
        "##life enjoyment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UBIi_wDzsO7",
        "outputId": "24c1d753-1bb9-4b12-a41f-480553e184a5"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'total_health', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'trauma',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0826499000926924"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGijRaH60euv"
      },
      "source": [
        "##resilience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u1sqDeGz1du",
        "outputId": "d73072a7-4b96-4bd6-e3c3-dccbccff5d01"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'total_health', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'trauma',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8119926583482817"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPjTwkM60hMV"
      },
      "source": [
        "##balanced life"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdroIh1Jz7md",
        "outputId": "b37268c3-f509-40c2-d777-19a88153f99c"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'total_health', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'trauma',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0442350149360973"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0trnw5BD0jsG"
      },
      "source": [
        "##emotional flexibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdpuuOqu0K5d",
        "outputId": "cff3d9f2-4d60-47eb-9443-7bb0a852d640"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'total_health', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'trauma',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.7217907433560047"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNNuiGgO0mKh"
      },
      "source": [
        "##self-actualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9v9XcDA0PHD",
        "outputId": "bc541cf2-1c21-410a-d775-947c3c33f5e5"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'total_health', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'trauma',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2145310870810677"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}