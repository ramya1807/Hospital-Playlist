{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Data Modeling for 28 Nov Meeting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOPKgdfR+8zBub9oV03pIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramya1807/Hospital-Playlist/blob/main/Data_Modeling_for_01_Dec_Meeting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hoLVd-svyUB"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV7-fnFoxnV-"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSPWSFA_vNcX",
        "outputId": "8c2e6f4a-2992-4133-9c2f-90af14ed87d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#and then to cd to any directory in the Google drive:\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/CDS 2021\")\n",
        "#and to list all items in the directory that Colab is working on (to make sure it's the right dir):\n",
        "\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "'(1) Dataset and Collection.ipynb'\n",
            "'(2) Data pre-processing'\n",
            "'(3) Problem and Algorithm Model'\n",
            "'(4) Evaluation Methodology'\n",
            "'(5) Results and Discussion'\n",
            "'CDS Midterm Proposal.pdf'\n",
            " data_cleaned2.csv\n",
            " data_cleaned.csv\n",
            "'data only'\n",
            " data_withgenre.csv\n",
            " genre.csv\n",
            "'GPU setup'\n",
            " lin-reg.ipynb\n",
            " literature\n",
            " master_new.csv\n",
            " master_spotify.csv\n",
            "'Meeting Notes.gdoc'\n",
            "'music and mental health GitHub repo'\n",
            "'Project Description.pdf'\n",
            "'Proposal Presentation Script and Outline.gdoc'\n",
            "'Results of Modelling.gsheet'\n",
            " songs_list.csv\n",
            "'songs mp3'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "Rb55wqxzxrwF",
        "outputId": "79397770-1468-4bf9-eb47-87c1353d7206"
      },
      "source": [
        "data = pd.read_csv('data_withgenre.csv')\n",
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>amount_music</th>\n",
              "      <th>life_enjoyment</th>\n",
              "      <th>resilience</th>\n",
              "      <th>balanced_life</th>\n",
              "      <th>emotional_flex</th>\n",
              "      <th>self_actualization</th>\n",
              "      <th>trauma</th>\n",
              "      <th>total_health</th>\n",
              "      <th>health_categorical</th>\n",
              "      <th>energy</th>\n",
              "      <th>dance</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>instrumental</th>\n",
              "      <th>acoustic</th>\n",
              "      <th>popularity</th>\n",
              "      <th>progressivetrance</th>\n",
              "      <th>anthemworship</th>\n",
              "      <th>christianmusic</th>\n",
              "      <th>popquebecois</th>\n",
              "      <th>earlymusic</th>\n",
              "      <th>talentshow</th>\n",
              "      <th>miamihiphop</th>\n",
              "      <th>basstrap</th>\n",
              "      <th>redneck</th>\n",
              "      <th>shimmerpop</th>\n",
              "      <th>ccm</th>\n",
              "      <th>electronictrap</th>\n",
              "      <th>deephouse</th>\n",
              "      <th>melodicmetalcore</th>\n",
              "      <th>canadianrock</th>\n",
              "      <th>compositionalambient</th>\n",
              "      <th>pixie</th>\n",
              "      <th>tropical</th>\n",
              "      <th>folkrock</th>\n",
              "      <th>canadianmetal</th>\n",
              "      <th>skatepunk</th>\n",
              "      <th>...</th>\n",
              "      <th>technicaldeathmetal</th>\n",
              "      <th>alternativehiphop</th>\n",
              "      <th>newromantic</th>\n",
              "      <th>southernrock</th>\n",
              "      <th>australianhiphop</th>\n",
              "      <th>melodicrap</th>\n",
              "      <th>mississippihiphop</th>\n",
              "      <th>escaperoom</th>\n",
              "      <th>upliftingtrance</th>\n",
              "      <th>undergroundhiphop</th>\n",
              "      <th>skarevival</th>\n",
              "      <th>dancehall</th>\n",
              "      <th>lilith</th>\n",
              "      <th>germanpoprock</th>\n",
              "      <th>strut</th>\n",
              "      <th>stompandholler</th>\n",
              "      <th>protopunk</th>\n",
              "      <th>boyband</th>\n",
              "      <th>shimmerpsych</th>\n",
              "      <th>hindihiphop</th>\n",
              "      <th>britishinvasion</th>\n",
              "      <th>peruvianrock</th>\n",
              "      <th>chicagorap</th>\n",
              "      <th>anti-folk</th>\n",
              "      <th>tracestep</th>\n",
              "      <th>softrock</th>\n",
              "      <th>gangsterrap</th>\n",
              "      <th>gothicmetal</th>\n",
              "      <th>cubaton</th>\n",
              "      <th>norwegianmetal</th>\n",
              "      <th>vaporsoul</th>\n",
              "      <th>alternativer&amp;b</th>\n",
              "      <th>punkblues</th>\n",
              "      <th>chillwave</th>\n",
              "      <th>newwave</th>\n",
              "      <th>garagerock</th>\n",
              "      <th>latinpop</th>\n",
              "      <th>slowcore</th>\n",
              "      <th>britishsoul</th>\n",
              "      <th>trance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.641</td>\n",
              "      <td>0.820</td>\n",
              "      <td>0.1020</td>\n",
              "      <td>0.395</td>\n",
              "      <td>117.974</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.0662</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.547</td>\n",
              "      <td>0.752</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>0.161</td>\n",
              "      <td>111.962</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.1130</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.655</td>\n",
              "      <td>0.526</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>0.156</td>\n",
              "      <td>121.127</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0566</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.774</td>\n",
              "      <td>0.692</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>0.771</td>\n",
              "      <td>128.033</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.516</td>\n",
              "      <td>0.631</td>\n",
              "      <td>0.2640</td>\n",
              "      <td>0.254</td>\n",
              "      <td>143.777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.7380</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0.0944</td>\n",
              "      <td>0.860</td>\n",
              "      <td>134.066</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.851</td>\n",
              "      <td>0.621</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.449</td>\n",
              "      <td>90.940</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.313</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.817</td>\n",
              "      <td>99.172</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.2480</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.442</td>\n",
              "      <td>0.574</td>\n",
              "      <td>0.1890</td>\n",
              "      <td>0.467</td>\n",
              "      <td>86.430</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.1900</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0.0491</td>\n",
              "      <td>0.490</td>\n",
              "      <td>151.836</td>\n",
              "      <td>0.006710</td>\n",
              "      <td>0.2720</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>551 rows × 406 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     gender  age  amount_music  ...  slowcore  britishsoul  trance\n",
              "0         1    1             1  ...       0.0          0.0     0.0\n",
              "1         1    1             1  ...       0.0          0.0     0.0\n",
              "2         1    1             1  ...       0.0          0.0     0.0\n",
              "3         0    1             0  ...       0.0          0.0     0.0\n",
              "4         1    1             2  ...       0.0          0.0     0.0\n",
              "..      ...  ...           ...  ...       ...          ...     ...\n",
              "546       0    1             2  ...       0.0          0.0     0.0\n",
              "547       0    1             2  ...       0.0          0.0     0.0\n",
              "548       1    1             2  ...       0.0          0.0     0.0\n",
              "549       1    1             2  ...       0.0          0.0     0.0\n",
              "550       1    1             2  ...       0.0          0.0     0.0\n",
              "\n",
              "[551 rows x 406 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsnbVlnEycCH",
        "outputId": "feb973ee-93bb-4920-9e8a-450b4671f078"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['gender', 'age', 'amount_music', 'life_enjoyment', 'resilience',\n",
              "       'balanced_life', 'emotional_flex', 'self_actualization', 'trauma',\n",
              "       'total_health',\n",
              "       ...\n",
              "       'vaporsoul', 'alternativer&b', 'punkblues', 'chillwave', 'newwave',\n",
              "       'garagerock', 'latinpop', 'slowcore', 'britishsoul', 'trance'],\n",
              "      dtype='object', length=406)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXcql3rPWyo8",
        "outputId": "1f411a15-3489-4393-9b18-f815f7da63ea"
      },
      "source": [
        "data['genres'] = 0\n",
        "data['genres']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "546    0\n",
              "547    0\n",
              "548    0\n",
              "549    0\n",
              "550    0\n",
              "Name: genres, Length: 551, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKUCISqvv1GG"
      },
      "source": [
        "# Data Preprocessing via Pipeline\n",
        "* standardScaler()\n",
        "* PCA()\n",
        "* FunctionTransformer\n",
        "* Normalizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7cShZZgv6_T"
      },
      "source": [
        "#from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "#from sklearn.decomposition import PCA\n",
        "#from sklearn.preprocessing import FunctionTransformer\n",
        " \n",
        "#pipeline = Pipeline([('pca', PCA()), ('fselect', FunctionTransformer(all_but_first_column))])\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p5_1Y60vXNd"
      },
      "source": [
        "# To Model\n",
        "* Decision Trees\n",
        "  * Predict trauma \n",
        "  * Predict specific mental health indicators \n",
        "      * Don’t use other mental health indicators as predictors\n",
        "* Ensemble Classifier\n",
        "  * Predict trauma \n",
        "  * Predict specific mental health indicators \n",
        "      * Don’t use other mental health indicators as predictors\n",
        "* Ridge Regression\n",
        "  * Predict trauma \n",
        "      * Don’t use other mental health indicators as predictors\n",
        "  * Predict specific mental health indicators \n",
        "      * Don’t use other mental health indicators as predictors\n",
        "* Lasso Regression\n",
        "  * Predict trauma \n",
        "      * Don’t use other mental health indicators as predictors\n",
        "  * Predict specific mental health indicators \n",
        "      * Don’t use other mental health indicators as predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddu8Or71v7mF"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBNgxT25v9aM",
        "outputId": "dfbfe499-5003-410b-cd89-5dc8d92d38c0"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['gender', 'age', 'amount_music', 'life_enjoyment', 'resilience',\n",
              "       'balanced_life', 'emotional_flex', 'self_actualization', 'trauma',\n",
              "       'total_health',\n",
              "       ...\n",
              "       'vaporsoul', 'alternativer&b', 'punkblues', 'chillwave', 'newwave',\n",
              "       'garagerock', 'latinpop', 'slowcore', 'britishsoul', 'trance'],\n",
              "      dtype='object', length=406)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MS80gSRv-AW"
      },
      "source": [
        "### Predict trauma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtGm7J3pTuu9"
      },
      "source": [
        "#### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "bOLkyZI_So0E",
        "outputId": "ae00f440-7158-4816-9b64-cb585c623c70"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_1 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_1.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_on_training_set(y_test, y_pred):  \n",
        "  # print out recall and precision\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  \n",
        "  # print out confusion matrix\n",
        "  print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred = model_1.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.99      0.77       104\n",
            "           1       0.67      0.03      0.06        62\n",
            "\n",
            "    accuracy                           0.63       166\n",
            "   macro avg       0.65      0.51      0.42       166\n",
            "weighted avg       0.64      0.63      0.51       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[103   1]\n",
            " [ 60   2]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(186.0, 190.26, 'X[5] <= 0.897\\ngini = 0.479\\nsamples = 385\\nvalue = [232, 153]'),\n",
              " Text(111.60000000000001, 135.9, 'X[3] <= 0.928\\ngini = 0.474\\nsamples = 374\\nvalue = [230, 144]'),\n",
              " Text(74.4, 81.53999999999999, 'X[0] <= 0.912\\ngini = 0.47\\nsamples = 369\\nvalue = [230, 139]'),\n",
              " Text(37.2, 27.180000000000007, 'gini = 0.48\\nsamples = 338\\nvalue = [203, 135]'),\n",
              " Text(111.60000000000001, 27.180000000000007, 'gini = 0.225\\nsamples = 31\\nvalue = [27, 4]'),\n",
              " Text(148.8, 81.53999999999999, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
              " Text(260.40000000000003, 135.9, 'X[385] <= 0.5\\ngini = 0.298\\nsamples = 11\\nvalue = [2, 9]'),\n",
              " Text(223.20000000000002, 81.53999999999999, 'X[0] <= 0.482\\ngini = 0.18\\nsamples = 10\\nvalue = [1, 9]'),\n",
              " Text(186.0, 27.180000000000007, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
              " Text(260.40000000000003, 27.180000000000007, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
              " Text(297.6, 81.53999999999999, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KufaFYDHT1Kc"
      },
      "source": [
        "#### PCA (undone)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mcFB88zTcCg"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7yqk0N5UJwD"
      },
      "source": [
        "#### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "FdOQ4fkWT-4F",
        "outputId": "1fddbcf9-38b7-4a32-9b8a-acedeb6c3288"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_3 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_3.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_3.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.99      0.77       104\n",
            "           1       0.67      0.03      0.06        62\n",
            "\n",
            "    accuracy                           0.63       166\n",
            "   macro avg       0.65      0.51      0.42       166\n",
            "weighted avg       0.64      0.63      0.51       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[103   1]\n",
            " [ 60   2]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(186.0, 190.26, 'X[5] <= 0.897\\ngini = 0.479\\nsamples = 385\\nvalue = [232, 153]'),\n",
              " Text(111.60000000000001, 135.9, 'X[3] <= 0.928\\ngini = 0.474\\nsamples = 374\\nvalue = [230, 144]'),\n",
              " Text(74.4, 81.53999999999999, 'X[0] <= 0.912\\ngini = 0.47\\nsamples = 369\\nvalue = [230, 139]'),\n",
              " Text(37.2, 27.180000000000007, 'gini = 0.48\\nsamples = 338\\nvalue = [203, 135]'),\n",
              " Text(111.60000000000001, 27.180000000000007, 'gini = 0.225\\nsamples = 31\\nvalue = [27, 4]'),\n",
              " Text(148.8, 81.53999999999999, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
              " Text(260.40000000000003, 135.9, 'X[265] <= 0.5\\ngini = 0.298\\nsamples = 11\\nvalue = [2, 9]'),\n",
              " Text(223.20000000000002, 81.53999999999999, 'X[5] <= 0.912\\ngini = 0.18\\nsamples = 10\\nvalue = [1, 9]'),\n",
              " Text(186.0, 27.180000000000007, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
              " Text(260.40000000000003, 27.180000000000007, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
              " Text(297.6, 81.53999999999999, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ5C3mD7UPgz"
      },
      "source": [
        "#### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "v5B0U6PzVtCs",
        "outputId": "91f7087a-3f11-487a-b6ea-b2ee6cfb86f0"
      },
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_4 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_4.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_4.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.99      0.77       104\n",
            "           1       0.67      0.03      0.06        62\n",
            "\n",
            "    accuracy                           0.63       166\n",
            "   macro avg       0.65      0.51      0.42       166\n",
            "weighted avg       0.64      0.63      0.51       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[103   1]\n",
            " [ 60   2]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(186.0, 190.26, 'X[5] <= 0.897\\ngini = 0.479\\nsamples = 385\\nvalue = [232, 153]'),\n",
              " Text(111.60000000000001, 135.9, 'X[3] <= 0.928\\ngini = 0.474\\nsamples = 374\\nvalue = [230, 144]'),\n",
              " Text(74.4, 81.53999999999999, 'X[0] <= 0.912\\ngini = 0.47\\nsamples = 369\\nvalue = [230, 139]'),\n",
              " Text(37.2, 27.180000000000007, 'gini = 0.48\\nsamples = 338\\nvalue = [203, 135]'),\n",
              " Text(111.60000000000001, 27.180000000000007, 'gini = 0.225\\nsamples = 31\\nvalue = [27, 4]'),\n",
              " Text(148.8, 81.53999999999999, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
              " Text(260.40000000000003, 135.9, 'X[265] <= 0.5\\ngini = 0.298\\nsamples = 11\\nvalue = [2, 9]'),\n",
              " Text(223.20000000000002, 81.53999999999999, 'X[3] <= 0.56\\ngini = 0.18\\nsamples = 10\\nvalue = [1, 9]'),\n",
              " Text(186.0, 27.180000000000007, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'),\n",
              " Text(260.40000000000003, 27.180000000000007, 'gini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
              " Text(297.6, 81.53999999999999, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoQnuBzrv_uQ"
      },
      "source": [
        "### Predict specific mental health indicators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox_mYboNXTKK",
        "outputId": "b9b68486-60a6-42ad-f4b5-1170096df5bc"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['gender', 'age', 'amount_music', 'life_enjoyment', 'resilience',\n",
              "       'balanced_life', 'emotional_flex', 'self_actualization', 'trauma',\n",
              "       'total_health',\n",
              "       ...\n",
              "       'alternativer&b', 'punkblues', 'chillwave', 'newwave', 'garagerock',\n",
              "       'latinpop', 'slowcore', 'britishsoul', 'trance', 'genres'],\n",
              "      dtype='object', length=407)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0m3X1nCW344"
      },
      "source": [
        "#### Life Enjoyment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMlSD5WvXJ_h"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uJqdX1YkXR43",
        "outputId": "1628e516-fdbb-42ca-bb85-830db0c747c6"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_5 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_5.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_5.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4\n",
            " 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3\n",
            " 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 4 4 4 3 3 3 4 3 3 4 3 3\n",
            " 3 4 3 3 3 3 3 3 4 3 4 4 4 3 3 3 4 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.00      0.00      0.00        28\n",
            "           3       0.29      0.90      0.44        48\n",
            "           4       0.20      0.11      0.14        36\n",
            "           5       0.00      0.00      0.00        26\n",
            "           6       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.28       166\n",
            "   macro avg       0.07      0.14      0.08       166\n",
            "weighted avg       0.13      0.28      0.16       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  4  1  0  0]\n",
            " [ 0  0  0 10  1  0  0]\n",
            " [ 0  0  0 25  3  0  0]\n",
            " [ 0  0  0 43  5  0  0]\n",
            " [ 0  0  0 32  4  0  0]\n",
            " [ 0  0  0 24  2  0  0]\n",
            " [ 0  0  0  8  4  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(223.20000000000002, 190.26, 'X[294] <= 0.5\\ngini = 0.799\\nsamples = 385\\nvalue = [14, 24, 60, 106, 98, 66, 17]'),\n",
              " Text(167.4, 135.9, 'X[391] <= 0.5\\ngini = 0.798\\nsamples = 381\\nvalue = [14, 24, 56, 106, 98, 66, 17]'),\n",
              " Text(111.60000000000001, 81.53999999999999, 'X[3] <= 0.701\\ngini = 0.799\\nsamples = 376\\nvalue = [14, 24, 56, 106, 93, 66, 17]'),\n",
              " Text(55.800000000000004, 27.180000000000007, 'gini = 0.793\\nsamples = 311\\nvalue = [12, 18, 47, 97, 70, 53, 14]'),\n",
              " Text(167.4, 27.180000000000007, 'gini = 0.785\\nsamples = 65\\nvalue = [2, 6, 9, 9, 23, 13, 3]'),\n",
              " Text(223.20000000000002, 81.53999999999999, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 0, 5, 0, 0]'),\n",
              " Text(279.0, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bq12KcmXMfO"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zmwiURL6XpAH",
        "outputId": "e812d5f3-00df-4fba-c38d-63f68128dfa4"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_6 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_6.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_6.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_6)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4\n",
            " 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3\n",
            " 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 4 4 4 3 3 3 4 3 3 4 3 3\n",
            " 3 4 3 3 3 3 3 3 4 3 4 4 4 3 3 3 4 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.00      0.00      0.00        28\n",
            "           3       0.29      0.90      0.44        48\n",
            "           4       0.20      0.11      0.14        36\n",
            "           5       0.00      0.00      0.00        26\n",
            "           6       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.28       166\n",
            "   macro avg       0.07      0.14      0.08       166\n",
            "weighted avg       0.13      0.28      0.16       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  4  1  0  0]\n",
            " [ 0  0  0 10  1  0  0]\n",
            " [ 0  0  0 25  3  0  0]\n",
            " [ 0  0  0 43  5  0  0]\n",
            " [ 0  0  0 32  4  0  0]\n",
            " [ 0  0  0 24  2  0  0]\n",
            " [ 0  0  0  8  4  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(223.20000000000002, 190.26, 'X[294] <= 0.5\\ngini = 0.799\\nsamples = 385\\nvalue = [14, 24, 60, 106, 98, 66, 17]'),\n",
              " Text(167.4, 135.9, 'X[391] <= 0.5\\ngini = 0.798\\nsamples = 381\\nvalue = [14, 24, 56, 106, 98, 66, 17]'),\n",
              " Text(111.60000000000001, 81.53999999999999, 'X[3] <= 0.701\\ngini = 0.799\\nsamples = 376\\nvalue = [14, 24, 56, 106, 93, 66, 17]'),\n",
              " Text(55.800000000000004, 27.180000000000007, 'gini = 0.793\\nsamples = 311\\nvalue = [12, 18, 47, 97, 70, 53, 14]'),\n",
              " Text(167.4, 27.180000000000007, 'gini = 0.785\\nsamples = 65\\nvalue = [2, 6, 9, 9, 23, 13, 3]'),\n",
              " Text(223.20000000000002, 81.53999999999999, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 0, 5, 0, 0]'),\n",
              " Text(279.0, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_xBOzBOXO4t"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yjBRcGeqX32L",
        "outputId": "6cdf3239-b970-4616-b099-5d0884d88790"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_7 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_7.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_7.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_7)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4\n",
            " 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3\n",
            " 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 4 4 4 3 3 3 4 3 3 4 3 3\n",
            " 3 4 3 3 3 3 3 3 4 3 4 4 4 3 3 3 4 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.00      0.00      0.00        28\n",
            "           3       0.29      0.90      0.44        48\n",
            "           4       0.20      0.11      0.14        36\n",
            "           5       0.00      0.00      0.00        26\n",
            "           6       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.28       166\n",
            "   macro avg       0.07      0.14      0.08       166\n",
            "weighted avg       0.13      0.28      0.16       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  4  1  0  0]\n",
            " [ 0  0  0 10  1  0  0]\n",
            " [ 0  0  0 25  3  0  0]\n",
            " [ 0  0  0 43  5  0  0]\n",
            " [ 0  0  0 32  4  0  0]\n",
            " [ 0  0  0 24  2  0  0]\n",
            " [ 0  0  0  8  4  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(223.20000000000002, 190.26, 'X[294] <= 0.5\\ngini = 0.799\\nsamples = 385\\nvalue = [14, 24, 60, 106, 98, 66, 17]'),\n",
              " Text(167.4, 135.9, 'X[391] <= 0.5\\ngini = 0.798\\nsamples = 381\\nvalue = [14, 24, 56, 106, 98, 66, 17]'),\n",
              " Text(111.60000000000001, 81.53999999999999, 'X[3] <= 0.701\\ngini = 0.799\\nsamples = 376\\nvalue = [14, 24, 56, 106, 93, 66, 17]'),\n",
              " Text(55.800000000000004, 27.180000000000007, 'gini = 0.793\\nsamples = 311\\nvalue = [12, 18, 47, 97, 70, 53, 14]'),\n",
              " Text(167.4, 27.180000000000007, 'gini = 0.785\\nsamples = 65\\nvalue = [2, 6, 9, 9, 23, 13, 3]'),\n",
              " Text(223.20000000000002, 81.53999999999999, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 0, 0, 0, 5, 0, 0]'),\n",
              " Text(279.0, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6E5dxNdW8Qa"
      },
      "source": [
        "#### Resilience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx7rmzyoYJ1K"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nNwfo0cvYFzo",
        "outputId": "74d1f9cc-6a5e-40d4-b036-56cde831deb5"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_8 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_8.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_8.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_8)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 4 5 4 2 5 5 4 4 5 4 4 5 4 4 4 5 4 5 4 2 5 4 4 5 4 5 5 4 2 4 4 5 4 4\n",
            " 4 4 2 4 4 2 5 2 2 5 5 4 4 4 4 4 4 4 5 4 5 4 4 4 5 4 5 4 5 4 5 4 5 5 2 4 4\n",
            " 5 4 5 4 4 4 2 5 4 4 4 5 4 5 4 4 2 4 4 2 5 4 5 4 2 5 5 4 4 5 5 5 5 5 4 5 4\n",
            " 4 4 4 2 5 5 5 4 5 4 4 4 5 2 5 4 5 4 4 4 5 4 5 5 4 4 4 5 5 4 5 4 4 4 4 4 4\n",
            " 5 4 4 4 4 4 4 2 4 4 4 4 4 2 5 5 4 4]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.19      0.17      0.18        18\n",
            "           3       0.00      0.00      0.00        23\n",
            "           4       0.30      0.62      0.41        47\n",
            "           5       0.46      0.51      0.49        49\n",
            "           6       0.00      0.00      0.00        26\n",
            "\n",
            "    accuracy                           0.34       166\n",
            "   macro avg       0.14      0.18      0.15       166\n",
            "weighted avg       0.24      0.34      0.28       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  2  0  0]\n",
            " [ 0  0  3  0 12  3  0]\n",
            " [ 0  0  3  0 16  4  0]\n",
            " [ 0  0  3  0 29 15  0]\n",
            " [ 0  0  4  0 20 25  0]\n",
            " [ 0  0  3  0 17  6  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(209.25, 190.26, 'X[146] <= 0.5\\ngini = 0.786\\nsamples = 385\\nvalue = [5, 11, 46, 74, 119, 91, 39]'),\n",
              " Text(167.4, 135.9, 'X[5] <= 0.0\\ngini = 0.784\\nsamples = 381\\nvalue = [5, 11, 42, 74, 119, 91, 39]'),\n",
              " Text(83.7, 81.53999999999999, 'X[3] <= 0.134\\ngini = 0.767\\nsamples = 254\\nvalue = [2, 4, 25, 48, 92, 51, 32]'),\n",
              " Text(41.85, 27.180000000000007, 'gini = 0.651\\nsamples = 13\\nvalue = [0, 0, 7, 2, 1, 1, 2]'),\n",
              " Text(125.55000000000001, 27.180000000000007, 'gini = 0.757\\nsamples = 241\\nvalue = [2, 4, 18, 46, 91, 50, 30]'),\n",
              " Text(251.10000000000002, 81.53999999999999, 'X[1] <= 0.715\\ngini = 0.789\\nsamples = 127\\nvalue = [3, 7, 17, 26, 27, 40, 7]'),\n",
              " Text(209.25, 27.180000000000007, 'gini = 0.764\\nsamples = 106\\nvalue = [1, 4, 9, 23, 26, 36, 7]'),\n",
              " Text(292.95, 27.180000000000007, 'gini = 0.766\\nsamples = 21\\nvalue = [2, 3, 8, 3, 1, 4, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hU1b34//ci93AxajBpc2gFIxbjDZLWBnsEPAJaQURQvxYVBJQiBQfLoZgfIMhVURMkHKSSElsQCwGCQKGCYWjlJEIEAuEWtQQKFDgTyIWQkGSyfn9MMs2QAAnMzJ7L5/U8eZ7Mnj1rf/bKymfWrL32GqW1RgghhHu0MjoAIYTwJ5J0hRDCjSTpCiGEG0nSFUIIN5KkK4QQbiRJVwgh3EiSrhBCuJEkXSGEcCNJukII4UaSdIUQwo0k6QohhBtJ0hVCCDeSpCuEEG4kSVcIIdxIkq4QQriRJF0hhHAjSbpCCOFGknSFEMKNJOkKIYQbSdIVQgg3CjQ6ACGuV1hY2OnKysooo+PwBaGhoWcqKiqijY7DHyj5NmDhrZRSWtqvcyil0Foro+PwBzK8IIQQbiRJV4irWLJkCSdOnGDevHm8//77HDhwgIyMDGbOnAlAeXk5AwYMACA9PZ3333+fS5cuMXLkyEZl1dbWcqWe+fTp03n77bftj8eMGcOiRYtccEbCaJJ0hbiKl156idGjR/PSSy8REhJCXFwcgwcPJiIiAoDVq1fzyCOPAJCVlUVgYCABAQE88MAD9jJKSkr4/e9/z3vvvUdNTQ0pKSmkpKSwYsUKACwWC126dOGuu+7CYrEAcPPNN3Pp0iU3n61wB0m6QlxFcXExrVu3pqysrMnn9+3bx9///ncOHDhA+/bt6datG7t373bYZ/78+VRXVzNu3DgCA5t37XrmzJlER0dz9OjRGz4H4Vkk6QpxFcuWLeOTTz5hzZo19m1ZWVmYzWaOHTvGe++9R8+ePYmLiyMmJoZNmzbRuXNnhzKmTp3K008/ze9//3uqqqowmUyYTCaef/55ACIjIzl8+DAFBQXU1NSQk5PDe++9x1dffcUPf/hDt56vcD2ZvSC8lrtnL6xdu5bOnTsTFxd31f2sVivvvPMOSUlJborsxsnsBfeRnq4QzTRw4EB7wt22bZvDcw0fBwQENEq4l18oS09PZ8iQIRw5coTXXnuNpKQkamtrmTVrFsuWLXPhWQijyc0RQjTT0qVLqaiooLa2FoCdO3cSGRlJ69atsVgs9OrVC6018+fPByAqKornn3/efqFMa43FYiEyMpJhw4Zx5swZOnfuTHV1NbW1tezbt4/i4mI6duxo5GkKF5OerhDNVFpayssvv2x/HBYWxogRI+wzDlrCarUSGBjIxYsXefzxx7n77ruprq6mW7dunDp1yplhCw8jPV0hmqlNmzYsXryYkJAQrFYrrVo17rMopTCZTA7b6i+UKaXo0aMHOTk5VFZW8tBDDxEYGEhWVhbh4eE899xzrF69mjZt2rjrlIQB5EKa8FruvpCWl5fHunXr6N+/P127dnXbcd1BLqS5jyRd4bVk7QXnkaTrPjK8IIQTpaenM3jw4BYNEezatYutW7fywAMPsGfPHpRSPPnkk8ydO5fHHnuMIUOGuDBi4W6SdIW4itTUVAICAhg0aBCffvop7dq1w2KxEBQUxOnTp6moqMBkMpGcnEx0dDQxMTFYrVYmTZpEeHg4cXFxWCwW+vXrR0xMDNnZ2Xz99dcADBgwgI4dO9KtWzeWLVtGSEgINTU1nDt3jvbt2xMRESG3Avsgmb0gxFV06tSJ0tJSKioqCA4O5vvvvyckJITx48cTHR1NYmIi58+fp3v37rRt25aamhr27t1LQEAAWmtiY2MpKiqyTzNrSkBAACkpKRQWFtKxY0fGjx/Pjh07WLBgARaLBavV6sYzFq4mPV0hrqK8vJyysjKOHTtGcHAw1dXVBAQEABAUFFQ/ForZbKZ9+/bExsYSHx/Ppk2biI6Opry8nLCwME6cOEGHDh1ITEwkMTHR4RgbNmwgOzub7t27s2vXLgoKCnjmmWeYM2cORUVF9uMJ3yAX0oTX8pQLaYWFheTn59OvXz+jQ7luciHNfSTpCq/lKUnXF0jSdR8Z0xU+yWw2k5+f3+LXjR49mjNnzjB06FDWr1/v8Fxubq59cfKtW7cyYcKERq8/deoUQ4cOBWxLOi5cuNDh+Z07d/LBBx8wZcoUAEwmU6M4J0+ezIYNG6ipqWHYsGHk5+fz7bffMm3aND7++GOHfZcuXcq0adM4dOiQw+Lq9crKykhOTmbWrFl89dVXvPPOO6xcuZIjR44wd+7cFtePuHGSdIXXW7hwIcXFxSxfvpyPPvqIqVOn2p9LTU0lPT2dkpISJk2a5LDoTFpaGikpKSxevNi+LS4ujrCwMNq1a9do5kBCQoJ9cfJHH32U22+/vVEsf/3rX/npT3/K+fPnycvLa7R+7s9+9jMSEhJ44oknyMrKavImi/rEHhgYyLBhwwDYs2cPI0aM4PDhww77FhUVMWrUKDZu3OiwuHq9tm3b0qlTJ8rKysjNzWXChAl8/fXX3HXXXXLnm0Ek6Qqv17ZtWzIyMujbty9VVVWcPHnS4fna2lqHGQXXmobVrl07FixYQEFBAVprqqurr7p/fXlFRUV8++23mM1mLly4wJ133kl4eDhnzpxxKCMnJ4cHH3yQffv2sWvXLnJzc68ZU58+fcjIyKCiogKr1Wqf0RAfH8+qVato3bp1kzGBbWpabGwsAwcO5MMPPyQ4OPiqxxKuJUlXeL3evXuzefNmwsPDKS0tpaqqyv7cqVOn2LFjB/Hx8VitVqKjowkJCQFgxIgRmEwmRo0a5VDeyZMnmTNnDrW1tRw9epSsrCwACgoKMJvN7Nixg9zcXMxmM/v37yctLQ2AW2+9ldmzZ9OzZ086dOjApUuXOHToEBcuXLCXAaC1tq/RMHjwYBISEuxlAGRmZvL5559jtVrJzMxkzZo11NTUYLVa6dOnD9u3b+e7776z719WVsaTTz7psLh6fXnHjx9n9uzZFBYWUlNTQ01NDY899piT/wKiJeRCmvBarriQNm/ePMaNG2dPzCUlJbRt27bJxW3qnTt3jltuueWKzzujjJbue619jhw5Ql5eHs8++ywgF9LcSZKu8Foye8F5JOm6j9wcIbxWaGjoGaVUlNFx+ILQ0NAzRsfgL6SnK0QzKaVaAZnAP7TWpmvt38KyFfBn4LzWetS19hfeSy6kCdF8vwMigYnOLrhunGQk0FMpNdTZ5QvPIT1dIZpBKdUL+BT4qdb6hAuPcw+wDfgvrfU+Vx1HGEd6ukJcg1IqBlgOvOjKhAugtc4HTMBqpdRNrjyWMIb0dIW4CqVUELae52at9cxr7e/E4/4PEAUMlikavkV6ukJc3VygBJjt5uOOBzoAb7j5uMLFZMqYEFeglBoEPA3Ea62vvAq5C2itLymlngF2KqV2aq3/7s7jC9eR4QUhmqCU6gx8BfxSa51rYByPAx8DCVrr00bFIZxHhheEuIxSqjWwGphqZMIF0FpvAv4ArFBKySdTHyA9XSEaqLtJ4ZO6h0M94SKWUioA2AR8o7V+0+h4xI2Rd04hHL0KdAUe9ISEC6C1tiqlhgDfKKWytdafGx2TuH7S0xWijlIqAVuP8iGtdYHR8VxOKZUIrAN+rrX+h9HxiOsjY7pCAEqpW4BVwGhPTLgAWutsYCaQoZQKNToecX2kpyv8Xt1CNuuBI1prj54XWzfm/BlQqrV+xeh4RMtJT1cIeBO4CduCNh6twcI4v1BKvWx0PKLlpKcr/JpS6r+AP2FbyObktfb3FEqpu4HtQG+t9V6j4xHNJz1d4bfqFrJZBrzgTQkXQGt9EBiHbXw34lr7C88hPV3hl5RSwYAZ2KC1dve6Ck6jlEoFYoCnPWWKm7g6SbrCLymlUoA7gAHuXlfBmZRSIcDfgAyt9Tyj4xHXJjdHCL+jlHoWeBIDFrJxtssWxvlaa/03o2MSVyc9XeFXlFI/Af4O9NVa7zY6HmdRSvXFtkZDgtb6X0bHI65MLqQJv6CUiqibYpUBJPlSwgXQWv8V22pkn8nCOJ5Nkq7wF48Cs4BzwAqDY3GVGUAltvMUHkqSrvAXLwA/AC4AAQbH4hJaayswBPh/SqkBRscjmiZjusIvKKUeA2q01luNjsXVlFIPYruteTbwV631IYNDEg1I0hXCx9SN6a4CegLJWuu3jY1INCTDC0L4nlrgENAGeN7gWMRlpKcrGgkLCztdWVkZZXQcviA0NPRMRUVFtBHHVkr9EPiJ1jrLiOOLpknSFY0opeSOUidRSqG1VkbHITyHDC8IIYQbySRqYbglS5bw2GOPsWLFClq1asVjjz3GsmXLiIqKYvTo0aSmptK3b1/uueceh9dZrVYCAhrP/kpLS+Po0aOYTCYiIyNZtWoVBw8e5Nlnn6VLly7uOq0W89dhHSOHYIwgPV1huJdeeonRo0fz0ksvERISQlxcHDfffDOVlZUopYiPj7fvW1NTw+rVq5k7dy7Hjh1j1apVpKSkkJKSQnV1NQCVlZWMHTsWs9kMwNmzZ5k6dSrbtm0z4vSarbKyMkprjb/9+NsbjSRdYbji4mJat25NWVmZfdvEiRPp2bMnO3bscNh348aNZGdnM3z4cDp16tSi49i+6cZ/Xf6mc603oenTp/P22/+ebZacnExSUpL9zU1cHxleEIZbtmwZn3zyCfPnzyc8PByAjz/+mLy8PKZOncrBgwft+w4YMIA+ffqwcuVKunfvzjPPPNOovNDQUFJTUxk3bhyZmZlERUUxY8aMJvf1dUuXLqWiooLaWttiajt37iQyMpLWrVtjsVjo1asXWmvmz58PQFRUFM8//zwWi4UuXbqgtcZisRAZGUlwcDADBgwgLy+PhIQEI0/Lq0nSFYZ74w3bd0FOnDiRtWvXcuDAAV555d/fubhp0yaHXm1YWBhDhw69YnkjRoyw//7UU0+5IGLvUVpayquvvkpaWhpgq7sRI0aQmppqcGT+S4YXhEeJiIggLi7O/njbtm0MHTqUH/3oR03uf/lH4PT0dIYMGcKRI0d47bXXSEpKora2FrPZzMyZM10ev6dp06YNixcvtl9wbNWq8b+8UgqTyYTJZOL55233UkRGRnL48GEKCgqoqakhJyeHqqoqPv/8c+6//363noOvkZ6uMJwzPwIPGzaMM2fO0LlzZ6qrq6mtraWiooKzZ88SEeF/XyWWkJDAunXr6N+/P127drVv/81vfnPN106dOtX+e3R0ND//+c9dEqO/kZ6uMFxpaSkvv/zvbxOv/whssVhaXJbVaiUwMJCLFy/y+OOPc/fdd/PFF19w7NgxzGYz/nbTx/3338/UqVMdEq4wlvR0heHqPwKHhIRgtVqv+hG4ofqPwEopevToQU5ODpWVlTz00EMEBgaSlZVFeHg4c+bMISAggNTUVL+fwXC59PR0Bg8eTJs2bVr0upSUFGJjY+nXr5+LIvNdchuwaMTdtwHn5eU1+RHYF7TkNmBn1HtqaioBAQEMGjSITz/9lHbt2mGxWAgKCuL06dNUVFRgMplITk4mOjqamJgYBg4cyJw5cwgPDycuLg6LxUK/fv2IiYkhOzubr7/+GrDNHOnYsSP79u3j22+/JSQkxClJ199ulZbhBWE4+QjsPJ06daK0tJSKigqCg4P5/vvvCQkJYfz48URHR5OYmMj58+fp3r07bdu2paamhr179xIQEIDWmtjYWIqKiuzj603Jzc0lLy+P3NxcN56Z75DhBeEVrudj8K5du9i6dSsPPPAAe/bsQSnFk08+yYoVK/j5z3/ukx+Ny8vLKSsr49ixYwQHB1NdXW2fuRAUFFTfq8RsNtO+fXtiY2OJj49n06ZNREdHU15eTlhYGCdOnKBDhw4kJiaSmJjocIzhw4dTWFhIfn6+Eafo9WR4QTTijuEFd3wMtlqtvPHGGwwYMICvvvqKc+fOkZSUxMWLF8nPz3dL0nX38EJz1CdMT3nTkeEFIdzAHR+DAwICSElJobCwkI4dOzJ+/PhGtxX7o9tvv91jEq4/kuEFYQh3fAzesGED2dnZdO/enV27dlFQUMCLL75IZmYmBw8e5PHHH29ylTIhXMroFYbkx/N+bM3CeEePHtXr1683OowbUleXN1zv27Zt0/v372/x8X/961/ryspK/eabb+rk5GSH51auXKmnTZumDx486LB937592mQyOWz78ssv9axZs/S2bdsctk+bNk1Pnz69RfsWFxfr119/3b69JXXkCz8yvCA8lr9+DF64cCHFxcUsX76cjz76yOHOsNTUVNLT0ykpKWHSpEkOt0CnpaWRkpLC4sWL7dvi4uLYv38/Tz31FEFBQQ7HaWrJy9raWnbv3s0dd9zhsO+hQ4dISkriwIED9m31dwTeddddDjeyXGvf6upqYmNjb6CGvJskXSE8TNu2bcnIyKBv375UVVVx8uRJh+dra2sdxrcvXbrU7LKtVitWq9Vhm1LKXsbhw4c5fvw4ZrOZkpKSJpdxbOp4Wutm7+vvJOmKFjGbzdc1VWj06NGcOXOGoUOHsn79eofncnNzGTlyJABbt25lwoQJjV5/6tQphg4dytmzZ5kzZw4zZsxweH7nzp188MEHTJkyBQCTydQozsmTJ7NhwwZqamoYNmwY+fn5fPvtt0ybNo2PP/7YYd+lS5cybdo0Dh06REZGRqPFcsrKykhOTmbWrFl89dVXvPPOO6xcuZIjR44wd+7cFtdPQ71792bz5s2Eh4dTWlpKVVWVQz3s2LGD+Ph4rFYr0dHRhISEALbV1UwmE6NGjXIo77777mPdunXU1NSwfft2vvvuOwD7kpc9e/a0r0J29913M2XKFHr27ElRURFZWbbvtOzSpQtz5swhLi7Ovm/DRXHKysqavW9kZOQN1Y/XM3p8Q34874e6scXU1FR9/vx5vWzZMr1o0SI9ZcoU+9jiggUL9NKlS3VxcbH+3e9+5zCut2TJEp2cnKw/+ugj+7YFCxbokpIS/Zvf/EavWrVKX27BggVN/l7vD3/4g8P2uXPnNtpn+/btOjs7W3/55Zc6PT290RhowzHi+vP485//rI8fP67feOMNh33nzZunT506pefNm3fFmDIzM/Xvfvc7nZycrGtqauxlNNwXJ43pXq93331XV1ZW2h8XFRU1uV9T24uLi7XVanXJvvPnz7c/bkkd+cKP9HTFFTn7Y267du1YsGABBQUFaN30x9GG6ssrKiri22+/xWw2889//pP169fz8MMPNyojJyeHBx98kH379rFr1y5yc3OvGVOfPn3IyMigoqLC4aN3fHw8q1atonXr1k3GBLb5wLGxsQwcOJAPP/yQ4ODgqx7rWkJDQ88opXDmz8SJEwkNDbU/vvXWW5vcr6ntERERBAQEuGTf119/3f44NDT0zA1VnJeRpCuuyNkfc0+ePMmcOXOora3l6NGj9o+jBQUFmM1mduzYQW5uLmazmf3799s/mt56663Mnj2bnj17EhAQwKJFizh48KBDGWD71Fa/MM7gwYNJSEiwlwGQmZnJ559/jtVqJTMzkzVr1lBTU4PVaqVPnz4OH73BNoTw5JNPkpWVhdls5tixY/byjh8/zuzZsyksLKSmpoaamhoee+yxG6rvioqKaK218rcff/pSSpA70kQTXHFn1Lx58xg3bpw9MZeUlNC2bdsmVxSrd+7cOW655ZYrPu+MMlq677X2OXLkCHl5eTz77LOA/91tJa5Nkq5oxF+/CtwV/O3rxcW1SdIVLqGUigEWAR2BEVrrnQaHdE1KqR8Di4EoYLjWeo/BIQkfJGO6wqmUUq2UUq8Ce4FvgHhvSLgAWutjwONAMrBZKTVHKRVqcFjCx0hPVziNUioW+BgIx9a79dq1/5RSUUAqcB+2c/nK4JCEj5CerrhhSqkApdRvgRzgc6C7NydcAK31Ga31M8CbwJ+VUqlKqbZGxyW8nyRdcUOUUvcA2cATwINa62SttfUaL/MaWus1wD3Yeu/5Sqkbmxcm/J4ML4jropQKBpKAMdh6g2lOn2fmYZRSvYHfA38D3tBaFxkckvBC0tMVLaaU+hmwG+gGPKC1XuLrCRdAa70FuBcoBvYrpQYr+Xph0ULS0xXNppQKB2YAvwJMwEp/SLZNUUolAmnAYWCM1vpfBockvIT0dEWzKKUeAfYDtwH3aq3/7K8JF0BrnQ10BQ4AeUqpl6XXK5pDerriqpRSEcA8oC8wWmu90eCQPI5S6n5svd7zwKta66MGhyQ8mPR0xRUppZ4E8oFq4B5JuE3TWucBPwe2ALuUUq8rpeTL10STpKcrGlFK3QZ8iO1C2Sta6+0Gh+Q1lFKdsd0gEgSM1FofNDgk4WGkpyvslM0QYB9wDLhfEm7LaK0LgF7AH4HtSqnJSqmga7xM+BHp6QoAlFIdsC1Q0wHbba+5Bofk9erqdDEQg20BnW8MDkl4AOnp+rm6BWp+jW3ebQ6QIAnXObTW/8R2p967wF+UUu8opcIMDksYTHq6fkwpdSewBAjG1ruV8UcXuWycfKTW+m8GhyQMIj1dP6SUClRKTcS2ZsIa4BeScF1La31Wa/3/gP8GPlVK/Y9Sqp3RcQn3k6TrZ+rmlOYAvYGfaq3n+9ICNZ5Oa70O2wI6gdhuJf6lwSEJN5PhBT+hlAoBJgOjgN8B6f58R5knqLvL72Pgf4HxWmuLwSEJN5Cerh+oWydgDxCHbRrYUkm4xtNaZ2FbJP0stl7vc3Irse+Tnq4PU0q1AWYCzwLjgNWSbD2TUupB4A/Ad9hutz5lcEjCRaSn66Pq1n7dD9yMbYGaDEm4nktr/TW2mQ17gL1KqZHS6/VN0tP1EXX/oLcCVuA94FFglNZ6s6GBiRZTSt2LrddbCryCbSGdMq11jaGBCaeQnq7veA7Yim2BmovYFqiRhOuFtNb7gUTgL8BOYBUw19CghNNIT9cH1I3dnq17+Cet9Sgj4xHOo5R6HZgC3AI8VLeOr/BigUYHIJwiCFsvdyu26UfCd6zH9smlr9GBCOeQnq4QQriRT/Z0w8LCTldWVkYZHYe3CA0NPVNRURFtdBz+Qtpn8/hqu/TJnq5SSmZHtYBSCq21TE9yE2mfzeOr7VJmLwghhBtJ0hVCCDeSpNsCS5Ys4cSJE8ybN4/333+fAwcOsHbtWn7729/yr3/9i7Fjx3LhwoVGr7Nam17EKzk5maSkJKqrqwHIyMhg5syZAKSnp/P6669z6dIl9u/fz/jx4113YsLrNdU2G7an999/n/z8/Eavu1LbTEtLY/LkyVgstjV4tm7dyltvvcXixYsdyh0zZgyLFi1y0Vn5Jkm6LfDSSy8xevRoXnrpJUJCQoiLi6Nbt2783//9HwEBAcTHx9v3rays5E9/+hNz586luLiYtLQ0UlJSWLx4sX2f4OBgBgwYQF5eHgCDBw8mIiICgPj4eHuD3717N3fccYcbz1R4m6ba5uXtqV5NTQ2rV69m7ty5HDt2jFWrVpGSkkJKSoq9A1BZWcnYsWMxm80APProo9x5553079/fodybb76ZS5cuufdkvZwk3RYoLi6mdevWlJWV2bf9+Mc/5vXXX+fUKcf1ST755BOOHz/Oa6+9xq233triY917770899xz5OTkcPz4ccxmMyUlJTd8DsI3NdU2r2Tjxo1kZ2czfPhwOnXq1OxjnDx5kh/+8IcO22bOnEl0dDRHjx5tccz+yienjLnKsmXL+OSTT5g/fz7h4eEALFq0iH379jF58mSHfUeNGkVxcTErVqxg4MCBjBgxolF5VVVVfP7550ydOpX169fTunVrzGYz/fv3Z8WKFfzjH/8gJSWFHj16kJqayk033eSW8xTep6m2mZWVZW9PDQ0YMIA+ffqwcuVKunfvzjPPPNOovNDQUFJTUxk3bhyZmZn06dOHsLCwRuWuWrWKwsJCBg4c6PqT9BEyZew6rV27ls6dOxMXF2ffNm/ePMaOHUtoaKhLj+1svjo1x1O5un021TY/+eQTevXqxY9+9COXHdfZfLVdStK9Qdu2baNXr15XfHy56dOno5Ri6tSpgO2C2ZYtW5g6dSrZ2dkUFRXx6quvkpaWhtlsJjMz0+Xn4KuN21N5a/ucP38+ERERDB06lBUrVhATE8Mrr7zisth9tV3K8MJ1WLp0KRUVFdTW1gKwc+dOIiMjad26NRaLhV69eqG1Zv78+QBERUXx/PPPY7FY6NKlC1prLBYLkZGRDBs2jDNnznDXXXcxa9Ys4uPjCQsLw2QyUVVVZeRpCi/livbZuXNnqqurqa2tJS8vjxEjRpCSkmLkaXotuZB2HUpLS3n55Zftj8PCwhgxYoR9tkFLWK1WAgNt733t27enW7du7N69m7y8PO677z6nxSz8hyva58WLF3n88ce5++676d27NxkZGVRUVDgzbL8hPd3r0KZNGxYvXkxISAhWq5VWrRq/dymlMJlMDtsiIyM5fPgwSil69OhBTk4OlZWVPPTQQwDExMSwadMmJk6cyNKlSxkzZoxbzkf4Fle0z8DAQLKysggPD6dv375YrVb69OnjrlPyKTKmex3y8vJYt24d/fv3p2vXri47jrv46tiZp5L22Ty+2i4l6bpIeno6gwcPpk2bNs1+zZYtW/jb3/7Gww8/TG5uLmFhYQwZMoRbb72VwYMH88c//rFF5TWXrzZuT2V0+7yetpmbm8tHH33EkiVLyMjIICcnh2HDhlFQUMC2bdvo168fffs6d8lfX22XMrzQTKmpqQQEBDBo0CA+/fRT2rVrh8ViISgoiNOnT1NRUYHJZCI5OZno6GhiYmKwWq1MmjSJ8PBw4uLisFgs9OvXj5iYGLKzs/n6668B27zJjh070rt3b7p168batWu5+eabOXfuHAEBAaxdu5aePXsaWwHCY7mjbSYkJPDAAw8AtjsnY2NjOXnyJE8//TTHjx+/6owI4UgupDVTp06dKC0tpaKiguDgYL7//ntCQkIYP3480dHRJCYmcv78ebp3707btm2pqalh7969BAQEoLUmNjaWoqIi+xXlpmitWbRoES+88AK//vWvGT58OOvWrQsPB64AABceSURBVOPAgQPk5OSQm5vrxjMW3sIdbbOhyspK1q9fbx/TvXTpEsHBwa48RZ8iPd1mKi8vp6ysjGPHjhEcHEx1dTUBAQEABAUF1X8Uwmw20759e2JjY4mPj2fTpk1ER0dTXl5OWFgYJ06coEOHDiQmJpKYmOhwjAULFlBcXMyePXs4fvw4O3fuZPjw4bz88sukp6eTkJBgxKkLD+eOtllQUIDZbKZr165kZmbStm1bDh48SOvWrbn99tsNOGvvJWO6TlRYWEh+fj79+vVz+7FvhK+OnXkqI9qnN7ZNX22XknSFzzZuTyXts3l8tV3KmK4QQriRXyVds9nc5ELO1zJ69GjOnDnDnDlzmDFjRqPnU1JS2LBhg8O25ORkxowZQ1VVFS+++CLLly9v9LrMzExSU1P57LPP+OCDD8jIyLA/Z7VaSUpKYtq0aZw9e7bJYy9cuJCUlBS+//57tm7dyoQJExod48MPP2TixIkUFBQwe/ZsUlNTOXnyZKNV0YRnuJE2WlJSQnJyMrNmzXJ4ruEC5A1NnjyZDRs2cOHCBVJSUnjqqaccnt+yZQtTpkxhy5Yt7Nmzh3feeYc9e/bYn6+qqmL27Nn89re/vWIZ8O//j1WrVjF9+nQOHTpkf67h60pKShrdsOGLfDbpLly4kOLiYpYvX85HH31kX8ADbFNs0tPTKSkpYdKkSbz99tv255pabDwuLo6oqCjefPPNRldp9+3bR4cOHRodf/z48dxzzz1UVlYSERHRaKHnU6dO2ZfgCw4O5sSJE/aFoQGKioro0qULISEhtGrVqsljR0REUFFRQatWrXj00UebvKDRrVs3iouL6dy5M0lJSZSXlxMTE0N0tM99yarXcXYbvemmm+jUqVOjNXUbLkDe0MiRIwHbHWwmk4nu3bs7PN+7d29MJhPHjh3jiy++IDQ01OHutuDgYJKSkrjtttuuWEbD/4+zZ88ydepUtm3bZn++4etuuukmYmNjW1SH3shnk27btm3JyMigb9++VFVVcfLkSYfna2trHabNNGf1+/Xr1/Pwww+jtbavsJ+bm0teXh65ubkOZXz33XeEhITQrl07FixYgMViwWq12vfJzs7m4MGD5ObmUl5ezgcffEB+fr79+dtuu43y8nIKCgoIDAxs8thDhgxh4sSJrFq1yiHOhnH84he/IDExkdraWpYuXcqgQYOuozaFK7iijQ4YMIDY2FisVqvDV/HUL0B+pTLq1/po2L4aTmG0WCyMHTuWLVu2OJSRk5NDly5drlhGw/+PekophzL8bZ0Rn026vXv3ZvPmzYSHh1NaWuqwYtepU6fYsWMH8fHxWK1WoqOjCQkJAWDEiBGYTCZGjRrlUN6pU6dYtGgRBw8e5OjRo2RlZQEwfPhwhg8fTkJCAmlpafb9TSYTpaWllJSUMGfOHM6ePYvVamXZsmUADBo0CJPJREJCAlarlXnz5vEf//EfDmXU1NQQHx/PxYsXmzz25s2beeutt4iPjyc3Nxez2cz+/fvtZZSVlTFr1iy++eYb9u7dy8aNGx0+HgpjObuNHj9+nNmzZ1NYWMj27dv57rvvALh48aJ9AfKG7SszM5PPP/8cq9VKVlYWjzzyiEP7ajiF8Ze//CXz5s3jjjvusJdx6dIlpkyZwj/+8Q+01k2W0fD/IyoqihkzZtCzZ0+HOOpf5ze01j73Yzst53n33Xd1ZWWl/XFxcbG2Wq2N9isqKrpqOZWVlbq8vPyq+1yrjCsduyVlnDhxQqelpdkf19WX4X83f/lxdvvUunEbvVIbcEf7ut4yiouL9fz58+2PfbVd+uSUsbCwsNOVlZVRRsfhLUJDQ89UVFTIIK+bSPtsHl9tlz6ZdN1BKdUKyAQKtdbjnFhuIJAFbNVav32t/YVoilLqSSAViNda/58Tyx0KvAn8VGt97W/BFI1I0r1OSqlJwACgh9baqV/xoJT6AZALDNda/9WZZQvfp5S6A8gGntRa57ig/N8DEcBzWhJIi0nSvQ5KqV7Ap9je7U+46Bg9gD8DP9NaH3fFMYTvUUqFAf8L/EFrvcBFxwgFdgB/1FrPd8UxfJkk3RZSSv0QWy90qNZ6i4uPNRF4GnjY2b1p4ZuUUkuA1sCvXNkLVUp1BHKAgVrr/3XVcXyRz04ZcwWlVBC23uciVyfcOvOA08D7bjiW8HJKqZeBh4BXXP2xX2t9FBgO/FkpdZsrj+VrpKfbAkqp94C7gX5a6+YtPnrjx4zA1rOerLX+zB3HFN5HKfUAsAXbNYaDbjzuLOBBoK/W2nqt/YX0dJtNKfU0MBh40V0JF0BrXVx33AVKqbvddVzhPeremDOAce5MuHWmAgqY5ubjei3p6TaDUupObBcOntBa7zIohuHAf2O7eHfBiBiE51FKKWANcFJr/RuDYrgN+AYYpbX+ixExeBNJuteglArHdsFgkdZ6kcGxpAHhuPgiifAeSqn/xvZJ6GGt9bUXZ3BdHA9hS/4Paq0LjYrDG0jSvYq6XsRSbF9r9KLRia7BdKA0rXWqkbEI4ymlHgZW4iHTCpVS44FfAb8w8g3A00nSvQql1CvA69jevcuNjgdcP/FdeAdPvIGmrpOyErBorUcbHY+nkqR7BUqpeGAztnftI0bH05BSagCwACff4im8Q92t4l8C27TW0wwOx4FSqh2wC5iptf6T0fF4Ikm6TVBK3YLtwsBErfWqa+1vBKXUO0BX4HGZquNflFLvAvcDv/TEv71S6l5s64c8orXeb3Q8nkamjF2mbiGbPwKZnppw6/x/QDC2KTvCTyilngKeA4Z4YsIFqEu0bwAZdT1f0YD0dC+jlEoCngB6aq2rjY7napRS0djG9UZqrTcbHY9wLaVULLYLqf201juNjudalFIfAZHAM0ZfhPYkknQbUEr9F7AMSNBan7zW/p5AKfWfwCpsF/uOGR2PcI26mSvZwMda64VGx9McdQvjfAUs11onGx2Pp5CkW0cpFYOt1/iC1vpLo+NpCaXUBOBZ4D9lqo5vUkr9AQjFNqzgNf+0Sqnbga+Bp7XWO4yNxjPImC4OC9mkelvCrfM+cAL4wOhAhPMppUYAPwde9aaEC1B3o8Rw4DNZGMdGerqAUuoDoDO2ua9uW1fBmZRSN2Hrqb+ltf7U6HiEcyilugJfYLvj7JDR8VwvpdRMIBHo46kXAN3F73u6SqnBwEDgJW9NuABa6xJst4POV0rFGR2PuHENFrL5jTcn3DpvARrw+6+g8uuerlLqLmwD/Y9rrXONjscZlFLDgEnId1h5NVd9B5+RGiyMM1prvcHoeIzit0lXKdUa2wD/Aq31YqPjcSal1MfATch3WHktV34Hn5GUUt2xvZn8XGv9D6PjMYJfJt26e8T/iO3jzlBfS0x1U3X+F/hEvsPK+9R9B98KbJ9W/ml0PM6mlDIBLwIPaa0rjY7H3fw16f4aGINtbutFo+NxBaVUJ2xLUj4l32HlPdz5HXxGqev0/Bko1lq/anQ87uZ3SVcplQBswvYuW2B0PK6klOoP/A+2hXHOGh2PuLq6qYtZwBattU9fcGqwMM5srfUnRsfjTn6TdJVSwdgumt0GTNBaZxgcklsopeYA/wmc0VoPMjoe0TSl1HTgHmyL1D/hzTNpmkspdQ+wDdgJjPf1TlA9f5oyFgc8AFQBxQbH4k7/Au4ABtT1pIRneh54DDjhDwm3TjG29vko0NvgWNzGn5LufwG1wELg7wbH4k7LsY2fKaCTwbGIK/sRtjVy3zE6EDc6iW3ebgnwuMGxuI3fDC+AbQDf12YqNJc/n7s38Pe/jz+dv18lXSGEMJo/DS8IIYThAp1VUFhY2OnKysooZ5XnLUJDQ89UVFREt/R1/lpfN6K5dS11e2XX214b8tf6dUbdgROHF/xoSMaBUgqttbqO1/llfd2I5ta11O2VXW97vawMv6xfZ9QdePDwwrZt2676+HLTp0/n7bf/PZ98zZo1vP/++1gsFl588UWWL19OTU0Nw4YNIz8/3yUxe7Ibrc/09HSGDBnCkSNH7PV54cIFUlJSeOqpp1wSsydzZn2mp6fz/vvvU11dzf79+xk/frxLYvZUrqrL+fPns3Ch533JhtOGF5xh6dKlVFRUUFtrm6a4c+dOIiMjad26NRaLhV69eqG1Zv5823ICUVFRPP/881gsFrp06YLWGovFQmRkJFu3buXOO+8kKCiIiIgILl26RGBgIMOGDTPwDN3LmfU5bNgwzpw5w1133WWvzzZt2mAymaiq8pn1WK7KVfU5a9Ys4uPj0Vqze/du7rjjDiNP0y1cXZfFxcXk5eXx4IMPGnmaTfKonm5paSkvv/yy/XFYWBgjRozAYrG0uKywsDAGDx7MX//6VxYsWIDFYsFq9a+1k51Zn1arlcBA23t0w/rMy8vjvvvuc1rMnsxV9dm+fXu6detGTk4Ox48fx2w2U1JS4rS4PZGr6/Lo0aPceeedhIeHc/asZ90B71E93TZt2rB48WJCQkKwWq20atX4PUEphclkctgWGRnJ4cOHUUrRo0cPcnJy+MlPfkJaWhoDBw5kzpw5FBUVERAQQGZmJrfccgv33HOPu07LMM6sz8rKSh566CEuXrzI/Pnz7fWZlZXFmDFj3HVKhnJFfQLExMSwadMmJk6cyMMPP0xqaio33XSTW87JKO6oy7/85S8cOnSIX/3qV245p+byqAtpeXl5rFu3jv79+9O1a1enxOVqnnwhzRvr82qMvpDmC/XpKRfSvLEunXUhzaOSrjfy5KTra4xOur7AU5KuN/L52QvXkp6ezoULF1r0mtzcXEaOHAnAl19+yeTJk9m7d68rwvMa11OPW7ZsYcqUKWzZYlvu1WQykZ+fT0ZGBjNnznRFmF7jRtvlqlWrmD59OocOHXKYgePPbrSNbt26lQkTJrgoupbzmDHd1NRUAgICGDRoEJ9++int2rXDYrEQFBTE6dOnqaiowGQykZycTHR0NDExMVitViZNmkR4eDhxcXFYLBb69etHTEwM2dnZfP311wAMGDCAjh07kpCQwAMPPABAt27d+OyzzwgODjbytJ3OHfXYu3dvunXrxtq1a8nKyrJ/PBw8eDCpqalGnr7Tubtdnj17lqlTp7Jo0SLy8/PtM3B8ibvb6MiRIzl8+LDBZ/1vHtPT7dSpE6WlpVRUVBAcHMz3339PSEgI48ePJzo6msTERM6fP0/37t1p27YtNTU17N27l4CAALTWxMbGUlRUZJ+Cci0333wzs2fP5rvvvnPxmbmXO+pRa82iRYt44YUX2LdvH7t27SI31ye+17MRd7fLekophxk4vsTdbdTTeExPt7y8nLKyMo4dO0ZwcDDV1dUEBAQAEBQUVD+egtlspn379sTGxhIfH8+mTZuIjo6mvLycsLAwTpw4QYcOHUhMTCQxMdHhGAUFBZjNZrp27UphYSG5ubm8+OKLRpyuy7ijHhcsWEBxcTF79uzBZDJhNpuJjIwkKysLs9lM//79+fGPf2zE6Tudu9tlVFQUM2bM4JlnniEwMJC0tDSGDBlixKm7jLvbaFBQEGazmR49enDvvfcaccoOvOpCWmFhIfn5+fTr18+lx2kJb7yQ5on12ByeeiHNm+rTWy6keWKdyuwFD+GNSddbeWrS9SbeknQ9kVfNXjCbzde13sHo0aO5dOkSSUlJpKSkODzX8CpvvSutBXD51fZ6S5YsaXThx2Kx8NRTTzW6WpqRkcGECRPIz89n9erVbNiwocXn01w3Ul9nzpxhzpw5zJgxo9HzKSkpjeKurwOtNa+99hpJSUmNxsrqX7dnzx7eeecd9uzZY3/OarWSlJTEtGnTrri2xcKFC0lJSeH7779v8u9WVlZGcnIys2bN4sCBA7z99tusXr2ab775xukX5m60LV5p7Y6m6nbmzJlMmjSJ6upq+7aCggJmz55NamoqR44cYd68eSxbtszhdcnJyYwZM4aqqiqHtQTqNXxdU38TgA8//JABAwZQUlJinxnhDq5ou7t27WLOnDls2rTJvu1K7bWpfQEmT57c5P9sZmZmozaWlpbG5MmTsVgsjB07tsUzJ67F6Ul34cKFFBcXs3z5cj766COmTp1qfy41NZX09HRKSkqYNGmSw6IVaWlppKSksHjxYvu2uLg49u/fz1NPPdXoCm79Vd6Gi2PUrwXQvXt3h3179+6NyWTi2LFjDtubaoyRkZFNLuAyePBgXnjhBU6ePEl8fHwza+PanF1fUVFRvPnmm41mZezbt48OHTo0On7DOqiurqa2ttbh7qCGr/viiy8IDQ11eL6oqIguXboQEhJCcXFxk2tbREREUFFRQatWrZr8u7Vt25ZOnTpRVlbG9u3bmTJlCqdPn77henZ23YaEhDR5fleq29DQUO6//37y8vLs2zp37kxSUhLl5eXcddddVFdXc3mvcfz48dxzzz1UVlaSlZVFYGAgtm8tt2n4uqb+JgDjxo2je/fu3HTTTfaZEc7mrrbbrVs3Tp8+TUhIiMP2ptrrlfZt6n/91KlThIeHN9peWVnJ2LFjMZvNTv1fr+f0pNu2bVsyMjLo27cvVVVVnDx50uH52tpahyuRly5danbZVqu10foJSimHMurXAtBa23sHDa9kXul4TW1veLzKykrWr19Pnz59mh1vc7iivtavX8/DDz/sUAe5ubnk5eWRm5vbZBkXL17k8ccf5+677+b8+fNNvq7+nX/Lli32Mm677TbKy8spKCiw3/8OOBx7yJAhTJw4kVWrVtmfv/zvNmDAAGJjY+3POYMr22Jz6vYHP/gBubm5BAUFOWxfunQpgwbZvpg5KSmJS5cuOTz/3XffERISQrt27exrCezevdthn/rXNfU3Adub4a233trs87ke7mq7AQEBpKSkUFhYaC/jSu21qX0vV789OzubgwcPkpub2+Sbn6s4Pen27t2bzZs3Ex4eTmlpqcMKVKdOnWLHjh3Ex8djtVqJjo62vyONGDECk8nEqFGjHMq77777WLduHTU1NWzfvt0+xav+Km/Pnj1JS0uz75+VlcUjjzzC0aNHycrKAhyvZDbcNzMzE7PZzPnz5+3bL168yBdffMGaNWscjjdlyhS01hw8eNCj6+vUqVMsWrSIgwcPOtTB8OHDGT58OAkJCU3WwYULF8jKyiI/P59z5841+bpf/vKXzJs3jzvuuMOhjJqaGuLj44mIiCAzM5M1a9Y4HHvz5s289dZbxMfHN/l3O378OLNnz6awsJAePXowY8YMoqNveK1op9dtfX1dfn5Xqlur1UpkZCT33Xefffvu3bvZuHEje/bs4e9//zvTp0+3z1KoZzKZKC0tpaSkxL6WwO23324fhmj4uiv9TTZu3MgTTzxxw3V4Ne5quxs2bGDy5MlERUXZzzEwMLDJ9trUvmD7u33++edcunTJXo+DBg3CZDKRkJDAypUrKSsrA2yfUFJTU+nRo4drKk5r7ZQfW1HO9e677+rKykr746Kioib3a2p7cXGxtlqtzdpXa63PnTvX7H3/8pe/6F27dmmtta47b4+sr5bWwbVe5+4ycnNz9caNG+2Pm1vXnli3TbWv5ryuXmVlpS4vL29xGTU1NXrWrFn2x9fbXrUH129L9r1SPV6p/t99911dUVGhtXZO3WmtZfbCjZLZC+4jsxdunMxeuH7Omr3gtJsjQkNDzyil/PJ7k673df5YXzeiuXUtdXtl19teLy/DH+vXGXUH8hXsQgjhVh6z9oIQQvgDSbpCCOFGknSFEMKNJOkKIYQbSdIVQgg3kqQrhBBuJElXCCHcSJKuEEK4kSRdIYRwI0m6QgjhRpJ0hRDCjSTpCiGEG0nSFUIIN5KkK4QQbiRJVwgh3EiSrhBCuJEkXSGEcCNJukII4UaSdIUQwo0k6QohhBtJ0hVCCDeSpCuEEG70/wMAPFy0T1wcCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK8ANRuNYg0l"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "By0tF4v3YmXH",
        "outputId": "fe0b1095-2da7-489d-81e6-b23930247f27"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_9 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_9.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_9.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_9)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 4 5 4 2 5 5 4 4 5 4 4 5 4 4 4 5 4 5 4 2 5 4 4 5 4 5 5 4 2 4 4 5 4 4\n",
            " 4 4 2 4 4 2 5 2 2 5 5 4 4 4 4 4 4 4 5 4 5 4 4 4 5 4 5 4 5 4 5 4 5 5 2 4 4\n",
            " 5 4 5 4 4 4 2 5 4 4 4 5 4 5 4 4 2 4 4 2 5 4 5 4 2 5 5 4 4 5 5 5 5 5 4 5 4\n",
            " 4 4 4 2 5 5 5 4 5 4 4 4 5 2 5 4 5 4 4 4 5 4 5 5 4 4 4 5 5 4 5 4 4 4 4 4 4\n",
            " 5 4 4 4 4 4 4 2 4 4 4 4 4 2 5 5 4 4]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.19      0.17      0.18        18\n",
            "           3       0.00      0.00      0.00        23\n",
            "           4       0.30      0.62      0.41        47\n",
            "           5       0.46      0.51      0.49        49\n",
            "           6       0.00      0.00      0.00        26\n",
            "\n",
            "    accuracy                           0.34       166\n",
            "   macro avg       0.14      0.18      0.15       166\n",
            "weighted avg       0.24      0.34      0.28       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  2  0  0]\n",
            " [ 0  0  3  0 12  3  0]\n",
            " [ 0  0  3  0 16  4  0]\n",
            " [ 0  0  3  0 29 15  0]\n",
            " [ 0  0  4  0 20 25  0]\n",
            " [ 0  0  3  0 17  6  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(209.25, 190.26, 'X[146] <= 0.5\\ngini = 0.786\\nsamples = 385\\nvalue = [5, 11, 46, 74, 119, 91, 39]'),\n",
              " Text(167.4, 135.9, 'X[5] <= 0.0\\ngini = 0.784\\nsamples = 381\\nvalue = [5, 11, 42, 74, 119, 91, 39]'),\n",
              " Text(83.7, 81.53999999999999, 'X[3] <= 0.134\\ngini = 0.767\\nsamples = 254\\nvalue = [2, 4, 25, 48, 92, 51, 32]'),\n",
              " Text(41.85, 27.180000000000007, 'gini = 0.651\\nsamples = 13\\nvalue = [0, 0, 7, 2, 1, 1, 2]'),\n",
              " Text(125.55000000000001, 27.180000000000007, 'gini = 0.757\\nsamples = 241\\nvalue = [2, 4, 18, 46, 91, 50, 30]'),\n",
              " Text(251.10000000000002, 81.53999999999999, 'X[1] <= 0.715\\ngini = 0.789\\nsamples = 127\\nvalue = [3, 7, 17, 26, 27, 40, 7]'),\n",
              " Text(209.25, 27.180000000000007, 'gini = 0.764\\nsamples = 106\\nvalue = [1, 4, 9, 23, 26, 36, 7]'),\n",
              " Text(292.95, 27.180000000000007, 'gini = 0.766\\nsamples = 21\\nvalue = [2, 3, 8, 3, 1, 4, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMapkYa9YjJv"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cH2wVmS5YzhN",
        "outputId": "6cc9d8b3-07de-4836-d769-2e4d04adf9e6"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_10 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_10.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_10.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 4 5 4 2 5 5 4 4 5 4 4 5 4 4 4 5 4 5 4 2 5 4 4 5 4 5 5 4 2 4 4 5 4 4\n",
            " 4 4 2 4 4 2 5 2 2 5 5 4 4 4 4 4 4 4 5 4 5 4 4 4 5 4 5 4 5 4 5 4 5 5 2 4 4\n",
            " 5 4 5 4 4 4 2 5 4 4 4 5 4 5 4 4 2 4 4 2 5 4 5 4 2 5 5 4 4 5 5 5 5 5 4 5 4\n",
            " 4 4 4 2 5 5 5 4 5 4 4 4 5 2 5 4 5 4 4 4 5 4 5 5 4 4 4 5 5 4 5 4 4 4 4 4 4\n",
            " 5 4 4 4 4 4 4 2 4 4 4 4 4 2 5 5 4 4]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.19      0.17      0.18        18\n",
            "           3       0.00      0.00      0.00        23\n",
            "           4       0.30      0.62      0.41        47\n",
            "           5       0.46      0.51      0.49        49\n",
            "           6       0.00      0.00      0.00        26\n",
            "\n",
            "    accuracy                           0.34       166\n",
            "   macro avg       0.14      0.18      0.15       166\n",
            "weighted avg       0.24      0.34      0.28       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  2  0  0]\n",
            " [ 0  0  3  0 12  3  0]\n",
            " [ 0  0  3  0 16  4  0]\n",
            " [ 0  0  3  0 29 15  0]\n",
            " [ 0  0  4  0 20 25  0]\n",
            " [ 0  0  3  0 17  6  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(209.25, 190.26, 'X[146] <= 0.5\\ngini = 0.786\\nsamples = 385\\nvalue = [5, 11, 46, 74, 119, 91, 39]'),\n",
              " Text(167.4, 135.9, 'X[5] <= 0.0\\ngini = 0.784\\nsamples = 381\\nvalue = [5, 11, 42, 74, 119, 91, 39]'),\n",
              " Text(83.7, 81.53999999999999, 'X[3] <= 0.134\\ngini = 0.767\\nsamples = 254\\nvalue = [2, 4, 25, 48, 92, 51, 32]'),\n",
              " Text(41.85, 27.180000000000007, 'gini = 0.651\\nsamples = 13\\nvalue = [0, 0, 7, 2, 1, 1, 2]'),\n",
              " Text(125.55000000000001, 27.180000000000007, 'gini = 0.757\\nsamples = 241\\nvalue = [2, 4, 18, 46, 91, 50, 30]'),\n",
              " Text(251.10000000000002, 81.53999999999999, 'X[1] <= 0.715\\ngini = 0.789\\nsamples = 127\\nvalue = [3, 7, 17, 26, 27, 40, 7]'),\n",
              " Text(209.25, 27.180000000000007, 'gini = 0.764\\nsamples = 106\\nvalue = [1, 4, 9, 23, 26, 36, 7]'),\n",
              " Text(292.95, 27.180000000000007, 'gini = 0.766\\nsamples = 21\\nvalue = [2, 3, 8, 3, 1, 4, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHV8-3M9XBAb"
      },
      "source": [
        "#### Balanced Life"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-zq2nLFsGGO"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_xmkWcjuxqxT",
        "outputId": "7b88a5ba-16f7-4597-cae5-0f2071dbe2db"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_11 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_11.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_11.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_11)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 5 5 2 3 4 2 4 3 4 3 4 3 3 3 3 2 4 5 2 4 4 3 3 3 3 2 3 4 5 3 3 3 4 3 3 3\n",
            " 3 4 3 4 5 4 3 3 3 3 2 3 5 3 3 4 3 4 4 3 3 3 3 3 3 3 4 5 3 2 4 4 3 3 4 3 5\n",
            " 3 3 3 3 3 3 3 3 5 3 4 4 5 3 4 5 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 2 3\n",
            " 3 5 3 3 4 4 4 5 4 3 3 4 3 2 3 3 3 3 4 3 3 3 2 5 3 3 4 3 3 3 3 3 3 3 5 3 4\n",
            " 3 3 5 3 3 3 3 5 3 3 3 3 5 4 3 2 3 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.09      0.03      0.04        36\n",
            "           3       0.24      0.69      0.36        36\n",
            "           4       0.21      0.22      0.22        32\n",
            "           5       0.28      0.13      0.18        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.23       166\n",
            "   macro avg       0.12      0.15      0.11       166\n",
            "weighted avg       0.18      0.23      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  1  0  0]\n",
            " [ 0  0  2  2  0  2  0]\n",
            " [ 0  0  1 22  7  6  0]\n",
            " [ 0  0  1 25  9  1  0]\n",
            " [ 0  0  2 21  7  2  0]\n",
            " [ 0  0  4 23  6  5  0]\n",
            " [ 0  0  0 11  3  2  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[4] <= 93.007\\ngini = 0.798\\nsamples = 385\\nvalue = [4, 16, 83, 76, 103, 75, 28]'),\n",
              " Text(83.7, 135.9, 'X[7] <= 52.5\\ngini = 0.713\\nsamples = 65\\nvalue = [1, 2, 14, 11, 29, 7, 1]'),\n",
              " Text(41.85, 81.53999999999999, 'X[3] <= 0.87\\ngini = 0.676\\nsamples = 19\\nvalue = [0, 1, 8, 1, 7, 1, 1]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.672\\nsamples = 16\\nvalue = [0, 1, 8, 1, 4, 1, 1]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0, 0]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[3] <= 0.633\\ngini = 0.689\\nsamples = 46\\nvalue = [1, 1, 6, 10, 22, 6, 0]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.73\\nsamples = 36\\nvalue = [1, 1, 4, 10, 14, 6, 0]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.32\\nsamples = 10\\nvalue = [0, 0, 2, 0, 8, 0, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'X[4] <= 105.039\\ngini = 0.804\\nsamples = 320\\nvalue = [3, 14, 69, 65, 74, 68, 27]'),\n",
              " Text(209.25, 81.53999999999999, 'X[5] <= 0.001\\ngini = 0.772\\nsamples = 59\\nvalue = [2, 4, 10, 8, 8, 23, 4]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.717\\nsamples = 49\\nvalue = [2, 2, 7, 8, 5, 23, 2]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.74\\nsamples = 10\\nvalue = [0, 2, 3, 0, 3, 0, 2]'),\n",
              " Text(292.95, 81.53999999999999, 'X[0] <= 0.412\\ngini = 0.798\\nsamples = 261\\nvalue = [1, 10, 59, 57, 66, 45, 23]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.737\\nsamples = 38\\nvalue = [0, 2, 11, 3, 14, 1, 7]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.795\\nsamples = 223\\nvalue = [1, 8, 48, 54, 52, 44, 16]')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LLfaA2jsKBV"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BVmDRmkrx7XG",
        "outputId": "4c7cab4b-8866-4edc-eafd-ca410ee705ff"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_12 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_12.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_12.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_12)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 5 5 2 3 4 2 4 3 4 3 4 3 3 3 3 2 4 5 2 4 4 3 3 3 3 2 3 4 5 3 3 3 4 3 3 3\n",
            " 3 4 3 4 5 4 3 3 3 3 2 3 5 3 3 4 3 4 4 3 3 3 3 3 3 3 4 5 3 2 4 4 3 3 4 3 5\n",
            " 3 3 3 3 3 3 3 3 5 3 4 4 5 3 4 5 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3\n",
            " 3 5 3 3 4 4 4 5 4 3 3 4 3 2 3 3 3 3 4 3 3 3 2 5 3 3 4 3 3 3 3 3 3 3 5 3 4\n",
            " 3 3 5 3 3 3 3 5 3 3 3 3 5 4 3 2 3 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.10      0.03      0.04        36\n",
            "           3       0.24      0.69      0.36        36\n",
            "           4       0.21      0.22      0.21        32\n",
            "           5       0.28      0.13      0.18        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.23       166\n",
            "   macro avg       0.12      0.15      0.11       166\n",
            "weighted avg       0.18      0.23      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  1  0  0]\n",
            " [ 0  0  2  2  0  2  0]\n",
            " [ 0  0  1 22  7  6  0]\n",
            " [ 0  0  1 25  9  1  0]\n",
            " [ 0  0  2 21  7  2  0]\n",
            " [ 0  0  3 23  7  5  0]\n",
            " [ 0  0  0 11  3  2  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[4] <= 93.007\\ngini = 0.798\\nsamples = 385\\nvalue = [4, 16, 83, 76, 103, 75, 28]'),\n",
              " Text(83.7, 135.9, 'X[7] <= 52.5\\ngini = 0.713\\nsamples = 65\\nvalue = [1, 2, 14, 11, 29, 7, 1]'),\n",
              " Text(41.85, 81.53999999999999, 'X[5] <= 0.018\\ngini = 0.676\\nsamples = 19\\nvalue = [0, 1, 8, 1, 7, 1, 1]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.672\\nsamples = 16\\nvalue = [0, 1, 8, 1, 4, 1, 1]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0, 0]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[3] <= 0.633\\ngini = 0.689\\nsamples = 46\\nvalue = [1, 1, 6, 10, 22, 6, 0]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.73\\nsamples = 36\\nvalue = [1, 1, 4, 10, 14, 6, 0]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.32\\nsamples = 10\\nvalue = [0, 0, 2, 0, 8, 0, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'X[4] <= 105.039\\ngini = 0.804\\nsamples = 320\\nvalue = [3, 14, 69, 65, 74, 68, 27]'),\n",
              " Text(209.25, 81.53999999999999, 'X[5] <= 0.001\\ngini = 0.772\\nsamples = 59\\nvalue = [2, 4, 10, 8, 8, 23, 4]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.717\\nsamples = 49\\nvalue = [2, 2, 7, 8, 5, 23, 2]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.74\\nsamples = 10\\nvalue = [0, 2, 3, 0, 3, 0, 2]'),\n",
              " Text(292.95, 81.53999999999999, 'X[0] <= 0.412\\ngini = 0.798\\nsamples = 261\\nvalue = [1, 10, 59, 57, 66, 45, 23]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.737\\nsamples = 38\\nvalue = [0, 2, 11, 3, 14, 1, 7]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.795\\nsamples = 223\\nvalue = [1, 8, 48, 54, 52, 44, 16]')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okmu3a0CsNQE"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HqS3NcMByHok",
        "outputId": "e6f4ad67-ab9a-4427-bfa5-513c2a2f3719"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_13 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_13.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_13.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_13)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 5 5 2 3 4 2 4 3 4 3 4 3 3 3 3 2 4 5 2 4 4 3 3 3 3 2 3 4 5 3 3 3 4 3 3 3\n",
            " 3 4 3 4 5 4 3 3 3 3 2 3 5 3 3 4 3 4 4 3 3 3 3 3 3 3 4 5 3 2 4 4 3 3 4 3 5\n",
            " 3 3 3 3 3 3 3 3 5 3 4 4 5 3 4 5 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3\n",
            " 3 5 3 3 4 4 4 5 4 3 3 4 3 2 3 3 3 3 4 3 3 3 2 5 3 3 4 3 3 3 3 3 3 3 5 3 4\n",
            " 3 3 5 3 3 3 3 5 3 3 3 3 5 4 3 2 3 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.10      0.03      0.04        36\n",
            "           3       0.24      0.69      0.36        36\n",
            "           4       0.21      0.22      0.21        32\n",
            "           5       0.28      0.13      0.18        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.23       166\n",
            "   macro avg       0.12      0.15      0.11       166\n",
            "weighted avg       0.18      0.23      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  1  0  0]\n",
            " [ 0  0  2  2  0  2  0]\n",
            " [ 0  0  1 22  7  6  0]\n",
            " [ 0  0  1 25  9  1  0]\n",
            " [ 0  0  2 21  7  2  0]\n",
            " [ 0  0  3 23  7  5  0]\n",
            " [ 0  0  0 11  3  2  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[4] <= 93.007\\ngini = 0.798\\nsamples = 385\\nvalue = [4, 16, 83, 76, 103, 75, 28]'),\n",
              " Text(83.7, 135.9, 'X[7] <= 52.5\\ngini = 0.713\\nsamples = 65\\nvalue = [1, 2, 14, 11, 29, 7, 1]'),\n",
              " Text(41.85, 81.53999999999999, 'X[5] <= 0.018\\ngini = 0.676\\nsamples = 19\\nvalue = [0, 1, 8, 1, 7, 1, 1]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.672\\nsamples = 16\\nvalue = [0, 1, 8, 1, 4, 1, 1]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0, 0]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[3] <= 0.633\\ngini = 0.689\\nsamples = 46\\nvalue = [1, 1, 6, 10, 22, 6, 0]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.73\\nsamples = 36\\nvalue = [1, 1, 4, 10, 14, 6, 0]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.32\\nsamples = 10\\nvalue = [0, 0, 2, 0, 8, 0, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'X[4] <= 105.039\\ngini = 0.804\\nsamples = 320\\nvalue = [3, 14, 69, 65, 74, 68, 27]'),\n",
              " Text(209.25, 81.53999999999999, 'X[5] <= 0.001\\ngini = 0.772\\nsamples = 59\\nvalue = [2, 4, 10, 8, 8, 23, 4]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.717\\nsamples = 49\\nvalue = [2, 2, 7, 8, 5, 23, 2]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.74\\nsamples = 10\\nvalue = [0, 2, 3, 0, 3, 0, 2]'),\n",
              " Text(292.95, 81.53999999999999, 'X[0] <= 0.412\\ngini = 0.798\\nsamples = 261\\nvalue = [1, 10, 59, 57, 66, 45, 23]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.737\\nsamples = 38\\nvalue = [0, 2, 11, 3, 14, 1, 7]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.795\\nsamples = 223\\nvalue = [1, 8, 48, 54, 52, 44, 16]')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyHuOklGXC3E"
      },
      "source": [
        "#### Emotional Flexibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLBFZHMsRQ1"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yaGXDJy1ybvq",
        "outputId": "7be5aedd-a2df-4167-d912-4f16a2a80d48"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_14 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_14.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_14.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_14)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 4 4 5 4 4 4 4 4 5 5 4 4 3 4 4 4 4 5 5 5 4 5 4 4 4 5 4 5 2 5 5 5 4 5\n",
            " 4 5 4 4 4 5 4 4 4 4 4 4 5 5 5 4 5 5 4 5 5 5 5 4 4 5 4 4 4 4 4 5 5 5 4 4 4\n",
            " 5 4 4 4 5 5 4 4 4 4 4 4 4 5 5 4 5 4 4 5 4 4 5 4 5 4 4 4 5 5 4 5 4 5 5 4 4\n",
            " 4 4 4 4 5 4 5 4 4 5 5 5 4 4 4 4 4 4 5 5 4 4 5 5 5 4 5 4 4 4 4 4 4 3 4 4 4\n",
            " 4 5 4 4 4 5 4 4 5 5 5 4 4 4 5 4 5 5]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       1.00      0.04      0.07        28\n",
            "           3       0.00      0.00      0.00        24\n",
            "           4       0.29      0.79      0.43        38\n",
            "           5       0.31      0.53      0.39        36\n",
            "           6       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.30       166\n",
            "   macro avg       0.23      0.19      0.13       166\n",
            "weighted avg       0.30      0.30      0.19       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  4  1  0]\n",
            " [ 0  0  0  0  7  4  0]\n",
            " [ 0  0  1  0 14 13  0]\n",
            " [ 0  0  0  0 18  6  0]\n",
            " [ 0  0  0  1 30  7  0]\n",
            " [ 0  0  0  0 17 19  0]\n",
            " [ 0  0  0  1 12 11  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(209.25, 190.26, 'X[146] <= 0.5\\ngini = 0.805\\nsamples = 385\\nvalue = [15, 19, 60, 71, 100, 95, 25]'),\n",
              " Text(167.4, 135.9, 'X[179] <= 0.5\\ngini = 0.804\\nsamples = 381\\nvalue = [15, 19, 56, 71, 100, 95, 25]'),\n",
              " Text(83.7, 81.53999999999999, 'X[4] <= 146.907\\ngini = 0.801\\nsamples = 296\\nvalue = [13, 17, 44, 53, 88, 65, 16]'),\n",
              " Text(41.85, 27.180000000000007, 'gini = 0.799\\nsamples = 252\\nvalue = [10, 14, 40, 45, 80, 47, 16]'),\n",
              " Text(125.55000000000001, 27.180000000000007, 'gini = 0.749\\nsamples = 44\\nvalue = [3, 3, 4, 8, 8, 18, 0]'),\n",
              " Text(251.10000000000002, 81.53999999999999, 'X[4] <= 183.509\\ngini = 0.778\\nsamples = 85\\nvalue = [2, 2, 12, 18, 12, 30, 9]'),\n",
              " Text(209.25, 27.180000000000007, 'gini = 0.773\\nsamples = 80\\nvalue = [2, 2, 12, 14, 11, 30, 9]'),\n",
              " Text(292.95, 27.180000000000007, 'gini = 0.32\\nsamples = 5\\nvalue = [0, 0, 0, 4, 1, 0, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 0, 4, 0, 0, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKxbVIpzsUd_"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7yWlQdHmyrQW",
        "outputId": "92acd198-1590-4112-cb0c-0a07083b9ccc"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_15 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_15.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_15.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_15)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 5 5 2 3 4 2 4 3 4 3 4 3 3 3 3 2 4 5 2 4 4 3 3 3 3 2 3 4 5 3 3 3 4 3 3 3\n",
            " 3 4 3 4 5 4 3 3 3 3 2 3 5 3 3 4 3 4 4 3 3 3 3 3 3 3 4 5 3 2 4 4 3 3 4 3 5\n",
            " 3 3 3 3 3 3 3 3 5 3 4 4 5 3 4 5 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3\n",
            " 3 5 3 3 4 4 4 5 4 3 3 4 3 2 3 3 3 3 4 3 3 3 2 5 3 3 4 3 3 3 3 3 3 3 5 3 4\n",
            " 3 3 5 3 3 3 3 5 3 3 3 3 5 4 3 2 3 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.10      0.03      0.04        36\n",
            "           3       0.24      0.69      0.36        36\n",
            "           4       0.21      0.22      0.21        32\n",
            "           5       0.28      0.13      0.18        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.23       166\n",
            "   macro avg       0.12      0.15      0.11       166\n",
            "weighted avg       0.18      0.23      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  1  0  0]\n",
            " [ 0  0  2  2  0  2  0]\n",
            " [ 0  0  1 22  7  6  0]\n",
            " [ 0  0  1 25  9  1  0]\n",
            " [ 0  0  2 21  7  2  0]\n",
            " [ 0  0  3 23  7  5  0]\n",
            " [ 0  0  0 11  3  2  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[4] <= 93.007\\ngini = 0.798\\nsamples = 385\\nvalue = [4, 16, 83, 76, 103, 75, 28]'),\n",
              " Text(83.7, 135.9, 'X[7] <= 52.5\\ngini = 0.713\\nsamples = 65\\nvalue = [1, 2, 14, 11, 29, 7, 1]'),\n",
              " Text(41.85, 81.53999999999999, 'X[5] <= 0.018\\ngini = 0.676\\nsamples = 19\\nvalue = [0, 1, 8, 1, 7, 1, 1]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.672\\nsamples = 16\\nvalue = [0, 1, 8, 1, 4, 1, 1]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0, 0]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[3] <= 0.633\\ngini = 0.689\\nsamples = 46\\nvalue = [1, 1, 6, 10, 22, 6, 0]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.73\\nsamples = 36\\nvalue = [1, 1, 4, 10, 14, 6, 0]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.32\\nsamples = 10\\nvalue = [0, 0, 2, 0, 8, 0, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'X[4] <= 105.039\\ngini = 0.804\\nsamples = 320\\nvalue = [3, 14, 69, 65, 74, 68, 27]'),\n",
              " Text(209.25, 81.53999999999999, 'X[5] <= 0.001\\ngini = 0.772\\nsamples = 59\\nvalue = [2, 4, 10, 8, 8, 23, 4]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.717\\nsamples = 49\\nvalue = [2, 2, 7, 8, 5, 23, 2]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.74\\nsamples = 10\\nvalue = [0, 2, 3, 0, 3, 0, 2]'),\n",
              " Text(292.95, 81.53999999999999, 'X[0] <= 0.412\\ngini = 0.798\\nsamples = 261\\nvalue = [1, 10, 59, 57, 66, 45, 23]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.737\\nsamples = 38\\nvalue = [0, 2, 11, 3, 14, 1, 7]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.795\\nsamples = 223\\nvalue = [1, 8, 48, 54, 52, 44, 16]')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXhV9ZXo8e8qERIiYGogRoxADPJSawQToygFjDRpraDF1qpttWCt9nXq7e3QaZ/rnZlO68x0xtuZuS3NVbQoWKFgCwhUW0As9Q00UAskggSwEUKLEZEgENb9Y+84B8jLOSfn7N/e56zP8/D4CDlnL37srPzO3muvJaqKMcaYYHzAdQDGGJNNLOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yALOkaY0yAclwHYLJDXl7e3iNHjhS5jqM7ubm5+9ra2s5xHYfJbKKqrmMwWUBENOznmoigquI6DpPZbKdrQmnp0qUUFBQwatQoVq9eTXFxMePGjWPt2rVMnjyZlpYWysrKWLBgAZWVlWzZsoXhw4fT3NzMnj17qKqqAqC8vNzx38SYk9lO1wQimZ1uU1MTTz75JBdddBENDQ2MGTOGiRMnsn37doYMGUJjYyOHDh2ioqKCdevW0dDQQGlpKQMGDODqq69OJkbb6Zq0s6RrApFo0q2rq6OkpIT8/HxaW1spKipi2bJl1NTUsH79ekpLS5k6dSqHDx8mJyeH/v37M3/+fAAuuugijh8/zuTJkxON0ZKuSTtLuiYQdk3XGI9d0zWBWbhwIWVlZezZs4fCwkIOHjzIpk2bmD17Nk1NTQwcOJDGxkZKS0tZvXo11dXVnDhxgvr6el555RVmzZrF0aNHWbRoEUOHDmX48OFUVlayePFiBgwYQL9+/bj88stZsWIFpaWlNDc3s2PHDqZPn87QoUNZvHgx7e3tjBgxgqqqKh577DHOO+88Dhw4wFlnneV6eUyWsJ2uCYSVjBnjsYcjTCDa2trOUVWJ5xfwYeAlYC0wMt7X+a89G3gY2AXUJvJaS7gmCLbTNaEhIv2A7wBfAb4LPKCqJ5J8r48CdcAzwD2q+teUBWpML9hO14SCiFQBG4FLgXGqWpdswgVQ1aeAi4BW4I8icqOI2E0y45ztdI1TIpIP/CNwC/A3wOOpLnMQkSuBB4CtwFdU9c1Uvr8xibCdrnFGRK4GNgNFwEWq+ot01JWp6npgHLAF2CQiX7Bdr3HFdromcCJyFvCvQC1wt6ouD/DYlwBzgb8Cd6rqzqCObQzYTtcETESmAa8C7Xi728ASLoCq1gOXAb8FXhKRr4tInyBjMNnNdromECIyBPgPvBtlX1TVtW4jAhEZBfw/vIeE7lDVLY5DMlnAdromrcTzWeCPwG6gPAwJF0BVG4DJwKPAOhH5noic4TYqk+lsp2vSRkRKgDlACTBTVTc4DqlLInI+8DPgXLxYNzoOyWQo2+malBORD4jI3cArwPNARZgTLoCq7gY+DvwIWCEi/ywieY7DMhnIdrompURkJF5NbD9glqr+yXFICRORIrzrz+PwrvWucxySySC20zUpISI5IvJt4DngCeDKKCZcAFXdp6o3Ad8GFojIT0RkoOu4TGawpGt6TUTKgReAjwKXqer/UdV2x2H1mqr+Cu9R4r7AqyLyccchmQxglxdM0vwGNd8DvgTMBh4KfafyJIlINV552R+Av1HVvzgOyUSU7XRNUkTkCrwbZR8GLlHVuZmacAFU9Xd4f9f9eA10brJHiU0ybKdrEiIiZwLfB24Cvg78MpOTbWdE5HLgQWA73mPMzY5DMhFiO10TNxGZiveQwwfxHuFdlG0JF0BVnwfGA/V4DXTusF2viZftdE2PRKQA+DegGrhLVVc6Dik0RORivF3vO3iPN+9wHJIJOdvpmm6JyA14DWoO4+1uLeHGUNXNwBXACuAFEbnHGuiY7thO13TKf0Dgv4ByvIccnnUcUuiJSBnegyF5eGv2quOQTAjZTtecxG9Q83m85uLb8RrUWMKNg6puB67G69e7RkTuFZG+jsMyIWM7XfM+ERmG1/TlHLydmjV9SZKInIfX7GcY3lq+6DgkExK20zUdDWq+gjcYch1QaQm3d1T1DeA64IfAUhH5kYj0dxyWCQHb6WY5v5H3g4Dg7ci2OQ4p44jIYODHeBMrvqiqaxyHZByynW6WEpEzROQ7wHrgcWCiJdz0UNX9qnoL8E1gnoj8TEQGuY7LuGFJNwuJyDi8BjVT8Hrd/qeqnnAcVsZT1WV4DXTAa6Bznct4jBt2eSGLiEgu8L+AO/DaFv48G58oCwMRmYLXQOdF4Buqut9xSCYgttPNEiJyJd5jqxcCF6vqw5Zw3fGv614MNOM10LnFHiXODrbTzXAiMgD4ATAD+JqqLnYckjmFiFyGdzNzF14DnT2OQzJpZDvdDCYiNXgNas7Ee4TXEm4I+TW8l+JdanhZRL4kIva9maFsp5uBROSDwP3AJOBOVX3KcUgmTiJyEd6utw2vvOw1xyGZFLOfphlGRG7Ea1DzNt7u1hJuhPj9GiYAvwaeE5H/KSI5jsMyKWQ73QwhIsV4DWrG4k2wXe84JNNLInIBUAcMxHtwZbPjkEwK2E434vwGNV8ANgFbgXGWcDOD35v3Grx+GL8TkX/w59KZCLOdboSJyHC8nVAhMFNV650GZNJGRIYCPwHK8Ha9zzsOySTJdroRJCJ9ROTrwAbgd3hjzy3hZjBV/TNwPfAPwK9E5H4RyXcclkmCJd2IEZExwLPAp4ArVfWfVfW447BMANTzON6jxIV4D1VUOw7LJMiSbkT4DWq+i5dwHwUmqWqD47CMA6r6F1X9HPBV4CEReUBEznIdl4mPJd0IEJFL8S4lXAWMV9WfWIMao6or8Ha9R4E/icj1jkMycbAbaSEmInnAvcAXgG8Bj1q/BNMZEfkI3ny2erzHvfc5Dsl0wXa6IeV/E20CRuA1qHnEEq7piqquwxsiuhPYLCKfswY64WQ73ZDxnyi7Bm/Uy1dU9VeOQzIRIyIVeI8S/xlYBDxiN1vDw3a6IeJfk1sEjMZ7hNcSrkmYqm4AKoAmvMnE/+Y0IHMSe6Y7XLYC/wTUqepbroMx0aWqx/xxTLvwLlOZkLDLC8YYEyDb6cYhLy9v75EjR4pcx9EhNzd3X1tb2zmu4zDuhO2cPJWdo12znW4cRCRUhQMigqraneksFrZz8lR2jnbNdroptHTpUgoKCigvL+f3v/89+fn5jBs3jrVr1zJ58mRaWlooKytjzpw5fOhDH+L48eOcffbZNDU1MW3aNNfhmwzVcV6OGjWK1atXU1xc3Ol5uWjRIoqLizl69CjPP/88X/va13jssccYNWoUe/fu5a233uKuu+5y/deJPNvpxiGRXUVTUxPFxcX069ePbdu2MXr06HTEY7uILJfoTjeI8zKWnaNds51uij311FOMGjWKw4cPc+aZZzJ69Gi2b9/OkCFDaGxs5NChQ1RUVLBu3TpaW1sZNWoUBw8eZMqUKa5DNxls+PDh1NXVvX9u7t+/n4kTJ552bhYUFLB582ba2tqoqqrizTffpLa21nX4GcV2unGId1dRV1dHSUkJ+fn5tLa2UlRUxLJly6ipqWH9+vWUlpYydepUDh8+TE5ODu3t7axcuZJjx45x4403UlhYGG88tovIconudBM9N/v378/8+fMZNGgQZWVlvPvuu0yePDmR+Owc7YIl3TiE7aaFndAmbOfkqewc7ZpdXojTwoULKSsrY8+ePRQWFnLw4EE2bdrE7NmzaWpqYuDAgTQ2NjJ27FjWrFnDhAkT2Lt3Ly0tLVxyySXs3r2bPn368PLLL3PttdfSr18/1qxZw7vvvkt1dTUFBQXMnTuXkpISCgsLqaqqYtWqVYwZM4Zhw4axYMEChg4dyqRJk1wvhQmJeM/Jc889l2eeeYba2lpOnDhBfX09u3btYvr06e9/2srLy2PkyJFUVlZy//33c8EFF3DWWWdRVVXFK6+8QnFxMc899xzV1dVs376dQ4cOsXr1au655x5ycnJYvnw5gwcPpri4mKKi0FayhYLtdOMQtppIq4E0YTsnT2XnaNcs6aaBiAwDXgRuVNVnu/iarwEzgQmq2hZkfCZ7+Z3H5gPv4c3VOy0BiMh5wEvALaq6JuAQM54l3RTzp7X+HviFqnbZaMQ/+RcAh1V1VlDxmewmIl8Bvoj3w/5wN193DTAPqPTns5kUsaSbYiLyE6AIb5fb7eKKyJl4O+IfqercIOIz2UtEqoBleAl3exxf/z2gFpiiqsfSHV+2sKSbQiJyK96kh0pVfTvO14wB1gFTbaKvSRcRKQQ2At+It2WoiHwAL0lvU9X/kc74sokl3RQRkQ8Ba4FqVd2c4Gs/A3wfqFDV1jSEZ7KYiPQBngQ2q+q3E3ztB/GS9bdUdXE64ss2lnRTQEQG4N14+KGq/jzJ9/hPoAS4IdQFmCZyRORe4Gq8DUHCEyT8SRQrgKtUtTHV8WUbS7q95N8QexxoVdU7e/E+ffEuMyxR1X9JVXwmu4lIDd70iApVfbMX73MX8GXg8u5uwJmeWdLtJRH5BvB54EpVPdLL9zof78baTar6TCriM9krleeTv7mYB5wAbrdPY8mzpNsLIjIBeALvp//OFL3nR4GH6OXOxGS3dHxyEpF84AXgP1S1LhXvmY0s6SZJRIbg3WC4W1WXp/i97wWq8a7BWamOSVi67hGIyCi8OvSP+QMwTYJsGnAS/LvBC4B5qU64vn8E3gV+kIb3NhlORG4BPkYaLgOoagNwN7DIr2wwCbKdbhJE5PvAFcBHVbU9Tcc4G28n/U1VfSIdxzCZR0TGAs8A16hq2qYAi8i/A6OA61T1RLqOk4lsp5sgEbkWuA24OV0JF0BV/wp8GviZiIxM13FM5vBLFxcD305nwvX9LTAI+E6aj5NxbKebABEZjncj4ZOquj6gY34Z+BJwhZXqmK741QWPAYdU9Y6AjjkUrz79c6r6uyCOmQks6cZJRHLxbiDMV9X7AzyuAI8CR+miK5QxrrrWicjVeF3LKqwxTnws6cZJROYAZwOfDjrx+aU6LwL3q+oDQR7bhJ+IXA4sxStdfN3B8f8OuBaYbNU2PbOkGwcR+RzwPbxGNgcdxTAaeBaoUdWXXcRgwkdEBuPdcP2qqi51FMMHgF8D21X1my5iiBJLuj0QkQ8Dq4GrVfWPjmP5NPBDvI9yb7mMxbjnly6uBF5W1dmOYynAS/5/q6qLXMYSdpZ0uyEiA/FuFHxfVR9xHQ+AiPwYGAFcb6U62U1E/h74CF5b0IQb2aQhnkuBVXiNcRpcxxNWlnS74N/AWgT8RVXvch1PB//xzrXAMlX9oeNwjCMiUgs8gPepZ6/reDqIyJ3A14EqVX3XdTxhZEm3CyJyD3AL3k/tXjWySTWbYZXd4pnB54q/WXkY6INXSmYJ5hSWdDshIlfhFZlXqWqT43A6ZTOsslO8M/hcEpH+wPPAT1X1p67jCRtLuqcQkSK8GwJ3quoK1/F0x2ZYZZ9EZvC55D9FuR64VlVfch1PmNhjwDFEJAfvqZ6Hwp5wfT8A3gbucx2IST9/Bt81ROAhGVV9DbgLrzHO2a7jCRPb6cYQkR8AlUBtOvsqpJLNsMoOvZnB55KI/AgYC3zCqm08ttP1ich1wGfxbk5FIuECqOoB4FPAT0XkQtfxmNSLaWTzrSglXN93gAHAd10HEha20wVEpBR4Dq/29TnX8STDZlhlplTN4HNJRM4FNgC3qerTruNxLeuTrt/IZj1eQ/Ifu44nWTbDKjOlcgafSyIyGe9+yWWqusdxOE5Z0hWpw+sL+pmoJyqbYZVZ0jGDzyURmQ1MByap6lHX8biS1UlXRG4HZuPVur7jOJyUsBlWmSGdM/hc8Rvj/ArYqarfcB2PK1mbdEWkHPgtXju6P7mOJ5VE5EbgX4FL/RttJkL8Rja/AV5U1b9zHU8q+Y1xNgDfVdVfuI7HhaxMuiIyCO8f/n+r6nzX8aSDiNwPXIjNsIocfwbfBLwZfM4b2aSaiIwDngI+oqpbXccTtKxLuv4NpyXAm6r6ZdfxpIuInIFX17lCVf/JcTgmTv4Mvp/hfUrZ5zqedBGRO4B78G6sHXIdT5CyMel+C2/g40RVfc91POnkz7DaAHzWZliFX8wMvhmq+nu30aSXv/mZC/QDbo36TexEZFXSFZGP4LVrvExVd7mOJwgiUo03Y81mWIVYzAy+Bar6767jCYLfGOc5oE5V/6/reIKSNUlXRM7Buxs8S1VXuY4nSDbDKvz8GXyFwKeyatcnUgb8Ae/ewwuu4wlCVjwG7Dey+QXwQLYlXN99wAHgX1wHYk7nz+CbQgQa2aSaqm4H7gQWikih63iCkBU7XRG5DxgHfDxKfRVSyWZYhVOYZvC5JCL/AlyM1woyo79HM36nKyLT8CZA3Jrp/5jd8QdZfgr4if8AhXHMn8H3S+CebE64vr8D8vCmbme0jN7pisgFeBfqp6nq867jCQObYRUOYZ3B55KIFONV28xU1d+4jiddMjbpikgeXsJ9UFX/03U8YWEzrMIhzDP4XBKRSXhd1S5T1d2u40mHjEy6InIWsB/vWlmtJZaT+aU6W4EzVdW6+gdMRH4DTATGhnUGn0si8kO8ByeqM7FeOVOv6V4C5AAPW8I9nd9v95fAB/0mJCZYE4BGICN3cinwONAXryNZxsnIna4xxoSV7XKMMSZAOa4DAMjLy9t75MiRIlfHz83N3dfW1naOq+Oniut1jJUJa2rr2XthWsPOuFjXUFxeEBGnl15FBFUVZwGkiOt1jJUJa2rr2XthWsPOuFhXu7xgjDEBCsXlhZ4sXbqUgoICBg0aRFNTE4MGDWLcuHGsXbuWyZMn09LSQllZGb/+9a8pLS1l7969DBkyhKamJurr67nnnnsYMGCA679GaHSs57Bhw3jmmWc4//zzu13PxsZGiouL2bFjB2+//TazZs0iLy/P9V8jFJI9N5ubm3nrrbe46aab6NOnj+u/Rmh0rOfAgQNpbm6mf//+3a7n0aNHOXToEK2trTQ3N3PHHXdwxhlnuP5rdCsSO91p06bx7LPPsm/fPs444wz27NnDwIEDGTt2LACtra2sXbuW0tJSduzYwcGDB9m3bx/nnHMO9957ryXcU3SsZ0NDA4WFhT2u56uvvsqxY8coKSnhq1/9qiXcGNOmTaOkpIRnn32WQYMG0dDQwKZNm5g2bRotLS0MGTKEDRs2MGjQIEaMGMGxY8fYvn07+fn5XHjhhZZwT9Fxbra0tAB0eW5WV1ezZ88e1q1bR2trKwMGDODuu+8OfcKFiFzTrauro6SkhPz8fFpbWykqKmLZsmXU1NSwfv16SktLmTp1KocPHyYnJ4eCggKWLFnCiRMnqKysZOTIkT0dP5LXy04V7/WzRNczLy+PJUuWAFBdXU1JSUk8sUR+TdO1nu3t7axatYrc3Ny4zk8/lkiuZ6LXdBNdy759+7J8+XLa29uZMmUK27Zto6amJpH4Al/XSCTdAI4fyRP6VK7XMVYmrKmtZ++FaQ0742JdQ3NNd+HChZSVlbFnzx4KCws5ePAgmzZtYvbs2TQ1NTFw4EAaGxvJy8ujubmZiooKTpw4QX19PRUVFbzwwgscP36cmpoaVqxYQUVFBSUlJaxatYoxY8YwbNgwFixYQHV1NUVFRcybN49hw4YxadIk13/1lIp3HceOHcuaNWuYMGHCSeu4ceNG+vXrx+WXX86KFSsoLS19f7337t1Lc3MzO3fuZMaMGRw7doyVK1e+/1F69+7d9O/fP6PWNN71LC4upr6+ngkTJtDW1saGDRuYNGkSu3fv5t133+WNN96gurqa5uZmNm/eTG1tLdu2bePAgQNcddVVNDQ00N7ezp/+9CdmzJiBqrJ69WqKi4sjv569OScbGhq4+eabOXbs2PufDkaOHEllZSX33Xcf1113HcePH2f06NEsX76csrIydu7cyZVXXvn+v8O2bdv44he/SE5ODsuXLyc3N5eLL76YQYMGOVmPUOx0XdfyRbUG8lSu1zFWJqyprWfvhWkNO5O1dbrJEJG/BwpU9ev+/38HGKGqd7qNLJpE5GW8BudP+///B+CHqrrMbWTRIyLnA68A56lqmz8qaitwvqq+4za66BGRu/Ca33zK///b8MYafcJtZMmJRPXCqUSkD/AF4MGY3/45cKOI5LuJKrpEZBxwNhA7MfhBYJabiCLvNuAXqtoGoKp7gWfwplCbxM3k5O/1XwITRORcR/H0SiSTLlAN7FfVTR2/oarNeAPubnQWVXTNBB5S1RMxv7cQmOzv0kyc/K5tM/HGi8ea6/++SYA/zqgYeLrj9/zm+7/E++EWOVFNurM4+SdfB9udJcgf/X0z8FDs7/sfg5cAn3MRV4RNAd4GXj7l91cApSIyJviQIm0WXovWU0dtPQjM9JvyR0rkkq6InA3UAI918sdPAqNE5MJgo4q064FXVHVXJ382l4ie2A7NBOaeWielqseBeXiXxUwcRKQfcCunbAh8LwJH8ZrBR0rkki7eP8KT/qDFk6jqUeAR7MRORFefGgDWAwJcEVw40eVPXL4WmN/Fl8wFPi8i4X9sKhymAX9U1ddP/QP/h1okP9lGKun6O67ukgR4J/ZtIhKaGuSwEpHheKPpf9XZn/sntl2LjN/NwCpV/Wtnf6iqDcBrwMcDjSq6Ors2HutRYLo/VTkyIpV0gfHAAGBtV1+gqluAXUBtQDFF2e3AYz0MRpwHzBCRM4MJKdJm0X2SwP/zyO3OgiYiJUAVsLirr1HVFryKm88EFVcqRC3pzuL0u+ydeRDbnXWri7K70/jlTuuwcqduicglQCEnl911ZhEw0R83brp2G/B4R9ldNyL3SSwySdcfqX4TXj1uTxYCU0QktE/ChMDVwF9VtT6Or43cie3ATDq/y34SVT2Et3v7fCBRRVBM2V23GwLfb4ASEflQeqNKncgkXeCTwEuq2uMEVVU9iHed8rNpjyq6ero2HmsFcIGIjE5jPJHll93dQud32TsT2XKngEwCDgEbe/pCvyrk50RoUxClpBvvT74ODwKz7MQ+nYh8EO+a94J4vl5Vj2HlTt2Zjld21xTn1z8PtANXpi2iaJsFPJhAe7K5wOdEpG8aY0qZSCRdESkFLgaWJvCy9UAfvIvx5mS3Ais6K7vrxkNYuVNXerrLfpKYqhC7oXYKETkL+ARdl92dRlW34/W2iEQvhkgkXby77PNV9b14X2AndrcS/dSAqm4DdgAfS0tEESUiw4BLgScSfOkjwA0iYmNNTnYz8JSq/iXB10WmZjf0Sde/y347CewkYszDmuCcRETGA2cBa5J4uf0QO11Hc5vuyu5Oo6r78P4NbkpLVNGV8IbA90vgChEZmuJ4Ui70SReYCuxT1c2JvlBV3wSeBT6V8qiiK96yu84sBD5i5U4e/y57j2V33YjM7iwIInIxUAT8NtHXquphvHK80DfBiULSTeh6WSes3Mnnl919Bng4mdf75U7WBOe/TQFaVfWVJF+/ChgmImNTGFOUxVV2141IVIWEOumKSCHwUTpvbhOvJ4ELrQkOADcAG+Ipu+uGVYX8t0TK7k4TxXKndIlpbvNwL97mJeAI8JFUxJQuoU66eP8Iy1S1Ndk3sHKnkyR7vSzWc8AJYELvw4kuv7nNx4mz7K4bHeVO2V4VMg3Y3Flzm3jFNMEJ9Q+x0CbdmOY2vbm00CHrm+CIyAigHPh1b97HqkLedwuwUlUP9OZNVPU1oIGIlDulUaq+1zua4LiZOhmH0CZdvDKcfLwxJ73ilzvtJLvLnW7Ha24Td9ldN+Zh5U69vdcQK6tvqPnNbSrx7hf0iqrux7sRF9omOGFOur25y96ZrL2hFm9zm3j55U5ZO/PLb25z6ky53oj0zK8UuJ34mtvEK9Tf66FMuiLSH69+8eEUvm3HzK9sbIJTDbTEzpRLgdBfO0ujzmbKJS1m5lfWNcFJQdldZ34DDBWRi1L4nikTyqSL19zmBVV9I1Vv6M/8eoLsLHdK1fWyWCuBEdk28yumuc3DKX7rbB2NNBl4h9NnyiXNLzkLbVVIWJNuKu6ydybryp1iZsr19i77SbJ45tf1wMtdzJTrjReAY8BVKX7fsJtJYs1t4vUQ8NkwNsEJXdIVkQuAi4BlaXj7P+DN/Lo8De8dVh0z5ZIuu+tGNjbBSeUNtPdlY1VIMs1t4uU3wdkCXJfq9+6t0CVdvJ1TQs1t4pVtJ3acM+WSFjPz69p0vH/Y+M1txtPFTLkUeAS4Pmozv3rhFuA3Xc2US4FQVoWEKun2srlNvLJp5lePM+VSINR3ilPsdnqeKZc0f+bXarKnCU5aPjXEWAxcLiLnpfEYCQtV0sV75LdZVf+YrgPEzPzKhiY4qS6760xWzPxK0132zoRyd5ZqIlIODCGJ5jbx8pvgLCRkTXDClnTT/ZOvQ8ZfYkhwplzSsmjmVzVwIM6Zcr0RuZlfSeptc5t4dVSFhCbXhSYQERmM18axN81t4tUx82tUAMdyJe6ZcikQie5OvZSuipqTZEMTHL+5TSIz5XrjJeAwIWqCE5qki3eXfamqvp3uA8U0wcnYE5uAkoQvo2d++TPlPkaKy+66MZeQljulyHRgk6ruTPeBwtgEJxRJN8XNbeKVseVOSc6US1oWVIXcQuIz5ZLmlzttI3Ob4AT9vf4oMC0sTXBCkXSBCiCPFDS3iVeGz/y6nTSV3XUjk2d+pa3srhuh2p2lioicj/f9nuhMuaT589aeJiRNcMKSdDvusqf6qZSeZNzuLKCyu9Nk6syvXs6U643FeE1wQj/zK0G3482US1Vzm3iF5nvdedL1m9t8mjTfZe9Cx8yvcxwcO12uIcmZcimQibuzlDa3iZffBGcRGVQVEmDZXWeeAs4VkQ87OPZJnNVKQGIAAAdDSURBVCddYAbwfCqb28QrZuZXxpzYBH+9LNYqYHimNMHxy+5uJvXNbeKVaU1wpgBvA8nOlEuaX5r2MCHYFIQh6bq4XhYrY8qdUjRTLmkx5U6h+BiXAtfT+5lyvfEi8B4hKnfqpVmkp7lNvDqa4PRzdHzAcdIVkTJgLOlpbhOv5/z/ZsLMr1uB5WlqbhOvh8icmV8uPzXEVoU43531VgpnyiVNVXcAr+K4CY7rne4XgEdV9airAMJYx5eMdDe3iZeqNpIBM79EZDhwCelrbhOvRwj5zK843QKsSmNzm3g5f8zaWdL177LfhsOdRIxHgE9GvNzpUuBMAiy760Ym7M6+ACwIuOzuNP7Mr98R/aqQoB7x78kSoMqfy+aEy51uDfBnVX3VYQzA+01woj7zaxYwN+i77F1YBFwV1ZlfqZ4plwLOd2e94c+UKyR1M+WS5jfBeRyHTXCcJF2/ROsHeHOhwmIR8B0RudB1IIkSkWvxxhA5u14Wyy93egqY6yewqPkx8G6KZ8r1xlNAqYh8z3UgiRKRfOC/gCcCaG4Tr18AXxeRy1wc3NVOdzRQDhx0dPzOHAAuAK52HUgSvow3rj4Mu9wOgvdpJopVIV8BQtWDFW+n+C3XQSShAK8nh9PLNKd4BxiMVw4YOHFRveE38vi8qj4Q+MG7ISK3EuAz9qni9yYtUNW1rmPp4O9wZ6lqnetYEiUiNwGr/eupoeD30xirqstdx5II/wbvnUCdw1Kx04jINLymO6meddfzsUO0DsYYk/Fcl4wZY0x2UdWEfuXm5u4F1NWv3NzcvZkSp+sYoxRrFGKMSpxRiLGneMMUX6Jrm/DlBRHp8dJMXV0do0aN4vDhw5x55plMnDiR7du3M2TIEBobGzl06BBnn302O3bsoL29ncGDB9O/f38qKiriOT6q2uPNmXjiTCTegoICmpub+djH4usEGU+cqY6xoqKCdevW8frrrzNr1izy8vICjzWeOMvKylizZg2HDh3ijjvu4Iwzen54LegYO9aytbWV8vJyjh8/Tnl5eWjj3L17NzNnzqRv3577nruK8fXXX6e6upqjR4/GtZbdxZvI906icTY0NFBaWkpJSQnjx4+P+xhdxXra16Qj6aZTOpJuOqQ66aZTFGKNQox+DKGPMwoxxkpF0g1KPGubk+qD1tXVUVJSQn5+Pq2trRQVFbFs2TJqampYv349paWlTJ06lcOHD5OTk0NBQQFLlizhyJEjVFdXU1IS3IMiicbav39/5s+fz1133RX6GHNzcwNdz2T/3fPy8hg7diwjR44MZZx5eXksWbKEvn37UllZGdo4o7KeHecnwDXXXENZWVnoYuzbty/Lly8nJyeHsrIympubmT59esriSWqn+/jjj1NWVsaePXsoLCzk4MGDbNq0idmzZ9PU1MTAgQNpbGwkLy+P5uZmKioqOHHiBPX19VRUVPDCCy9w/PhxampqWLFiBRUVFZSUlLB48WIqKioYNmwYCxYsoLq6mqKiIubNm8ewYcOYNGlSQjvdZOLctWsXBw8epLy8nC1btqCqVFVVsW7dOvr27cukSZNYtGgRw4cPp7Kykrq6OmpqaiguLmbOnDmUl5fHHaeI6MaNG3uMb+zYsaxZs4YJEyactI4HDhxg69at769jaWnpaeu9a9cupk+fTnt7OytXrmTatGm0tLSwe/du+vfvn1CsvV3PhoYGjh8/ftp6zpkzh0svvTQl6xlvjMXFxdTX1zNhwgT27t1LS0sLl1xyCfv37+e9995j9OjRPPHEE1xwwQVUVlYyZ84cZsyYweDBg/npT3/K+PHj2bt3L7W1taxZs4YRI0bw1ltvccUVV6RtLWPjbGpq4o033qC2tjauc3Pu3LmMGTMm7f/esTHu3r2bPn36sGXLFqqrq2lvb+fpp5+mtrb2tPOz44dGdXU1eXl5rFu3jvz8/C7jTSS+2O+fbdu2ceDAAa666ioOHDjAiy++yP79+7n11lt58803aWpqorm5mRtuuIHBgwdz3333MX78eAoKCqiqqno/R23cuJFJkyaxe/du3nnnHV577TXKysqYPHlyz/kpnptSsb+8l/Rs586deuTIkbi+Nh5bt25V9QLQTIkznhhTHV86Y1UN/3qmI0ZV1ba2Nm1qagp1nFFZyw7dxRuG+E61devWuNY24csLubm5+0SkKNHXpUpubu6+eL8u7HG6jjE2jni+xtazZ1GIMwoxxuos3jDFFyuetbWHI4wxJkD2cIQxxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTIkq4xxgTo/wM1312RAm+0SwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmTVBYjpsYJQ"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IBvYkiv2y4MK",
        "outputId": "7d13b6ed-e0c7-47f4-8aaa-3c851f93c00f"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_16 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_16.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_16.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_16)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 5 5 2 3 4 2 4 3 4 3 4 3 3 3 3 2 4 5 2 4 4 3 3 3 3 2 3 4 5 3 3 3 4 3 3 3\n",
            " 3 4 3 4 5 4 3 3 3 3 2 3 5 3 3 4 3 4 4 3 3 3 3 3 3 3 4 5 3 2 4 4 3 3 4 3 5\n",
            " 3 3 3 3 3 3 3 3 5 3 4 4 5 3 4 5 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 2 3\n",
            " 3 5 3 3 4 4 4 5 4 3 3 4 3 2 3 3 3 3 4 3 3 3 2 5 3 3 4 3 3 3 3 3 3 3 5 3 4\n",
            " 3 3 5 3 3 3 3 5 3 3 3 3 5 4 3 2 3 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.09      0.03      0.04        36\n",
            "           3       0.24      0.69      0.36        36\n",
            "           4       0.21      0.22      0.22        32\n",
            "           5       0.28      0.13      0.18        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.23       166\n",
            "   macro avg       0.12      0.15      0.11       166\n",
            "weighted avg       0.18      0.23      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  1  0  1  0  0]\n",
            " [ 0  0  2  2  0  2  0]\n",
            " [ 0  0  1 22  7  6  0]\n",
            " [ 0  0  1 25  9  1  0]\n",
            " [ 0  0  2 21  7  2  0]\n",
            " [ 0  0  4 23  6  5  0]\n",
            " [ 0  0  0 11  3  2  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[4] <= 93.007\\ngini = 0.798\\nsamples = 385\\nvalue = [4, 16, 83, 76, 103, 75, 28]'),\n",
              " Text(83.7, 135.9, 'X[7] <= 52.5\\ngini = 0.713\\nsamples = 65\\nvalue = [1, 2, 14, 11, 29, 7, 1]'),\n",
              " Text(41.85, 81.53999999999999, 'X[3] <= 0.87\\ngini = 0.676\\nsamples = 19\\nvalue = [0, 1, 8, 1, 7, 1, 1]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.672\\nsamples = 16\\nvalue = [0, 1, 8, 1, 4, 1, 1]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 0, 0, 3, 0, 0]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[3] <= 0.633\\ngini = 0.689\\nsamples = 46\\nvalue = [1, 1, 6, 10, 22, 6, 0]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.73\\nsamples = 36\\nvalue = [1, 1, 4, 10, 14, 6, 0]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.32\\nsamples = 10\\nvalue = [0, 0, 2, 0, 8, 0, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'X[4] <= 105.039\\ngini = 0.804\\nsamples = 320\\nvalue = [3, 14, 69, 65, 74, 68, 27]'),\n",
              " Text(209.25, 81.53999999999999, 'X[5] <= 0.001\\ngini = 0.772\\nsamples = 59\\nvalue = [2, 4, 10, 8, 8, 23, 4]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.717\\nsamples = 49\\nvalue = [2, 2, 7, 8, 5, 23, 2]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.74\\nsamples = 10\\nvalue = [0, 2, 3, 0, 3, 0, 2]'),\n",
              " Text(292.95, 81.53999999999999, 'X[0] <= 0.412\\ngini = 0.798\\nsamples = 261\\nvalue = [1, 10, 59, 57, 66, 45, 23]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.737\\nsamples = 38\\nvalue = [0, 2, 11, 3, 14, 1, 7]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.795\\nsamples = 223\\nvalue = [1, 8, 48, 54, 52, 44, 16]')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fmwk3XGXGZX"
      },
      "source": [
        "#### Self Actualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JOZ4BOxsbNm"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8BXeGxVlW3Ix",
        "outputId": "30e5e7e9-2907-40cd-899a-1c801d0a5eab"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'balanced_life',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_17 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_17.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_17.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_17)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 6 5\n",
            " 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.00      0.00      0.00        20\n",
            "           4       0.00      0.00      0.00        39\n",
            "           5       0.29      0.98      0.44        47\n",
            "           6       1.00      0.05      0.10        38\n",
            "\n",
            "    accuracy                           0.29       166\n",
            "   macro avg       0.18      0.15      0.08       166\n",
            "weighted avg       0.31      0.29      0.15       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  3  0]\n",
            " [ 0  0  0  0  0  7  0]\n",
            " [ 0  0  0  0  0 12  0]\n",
            " [ 0  0  0  0  0 20  0]\n",
            " [ 0  0  0  0  0 39  0]\n",
            " [ 0  0  1  0  0 46  0]\n",
            " [ 0  0  1  0  1 34  2]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[265] <= 0.5\\ngini = 0.781\\nsamples = 385\\nvalue = [2, 15, 27, 52, 100, 117, 72]'),\n",
              " Text(83.7, 135.9, 'X[200] <= 0.5\\ngini = 0.784\\nsamples = 372\\nvalue = [2, 15, 27, 52, 99, 108, 69]'),\n",
              " Text(41.85, 81.53999999999999, 'X[230] <= 0.5\\ngini = 0.781\\nsamples = 368\\nvalue = [2, 15, 24, 52, 99, 108, 68]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.785\\nsamples = 343\\nvalue = [1, 15, 23, 52, 94, 95, 63]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.646\\nsamples = 25\\nvalue = [1, 0, 1, 0, 5, 13, 5]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[2] <= 0.226\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 0, 0, 0, 1]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0, 0]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(251.10000000000002, 135.9, 'X[5] <= 0.03\\ngini = 0.462\\nsamples = 13\\nvalue = [0, 0, 0, 0, 1, 9, 3]'),\n",
              " Text(209.25, 81.53999999999999, 'X[234] <= 0.5\\ngini = 0.298\\nsamples = 11\\nvalue = [0, 0, 0, 0, 0, 9, 2]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.18\\nsamples = 10\\nvalue = [0, 0, 0, 0, 0, 9, 1]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(292.95, 81.53999999999999, 'X[4] <= 95.0\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 0, 0, 1, 0, 1]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0, 0]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GahaeYFwseAi"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JmktpuRvW1tQ",
        "outputId": "f3324a2d-61f8-46eb-80bb-dc36fb11224f"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'balanced_life',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_18 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_18.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_18.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_18)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 6 5\n",
            " 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.00      0.00      0.00        20\n",
            "           4       0.00      0.00      0.00        39\n",
            "           5       0.29      0.98      0.44        47\n",
            "           6       0.75      0.08      0.14        38\n",
            "\n",
            "    accuracy                           0.30       166\n",
            "   macro avg       0.15      0.15      0.08       166\n",
            "weighted avg       0.25      0.30      0.16       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  3  0]\n",
            " [ 0  0  0  0  0  7  0]\n",
            " [ 0  0  0  0  0 12  0]\n",
            " [ 0  0  0  0  0 20  0]\n",
            " [ 0  0  0  0  0 39  0]\n",
            " [ 0  0  0  0  0 46  1]\n",
            " [ 0  0  0  0  1 34  3]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[265] <= 0.5\\ngini = 0.781\\nsamples = 385\\nvalue = [2, 15, 27, 52, 100, 117, 72]'),\n",
              " Text(83.7, 135.9, 'X[200] <= 0.5\\ngini = 0.784\\nsamples = 372\\nvalue = [2, 15, 27, 52, 99, 108, 69]'),\n",
              " Text(41.85, 81.53999999999999, 'X[230] <= 0.5\\ngini = 0.781\\nsamples = 368\\nvalue = [2, 15, 24, 52, 99, 108, 68]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.785\\nsamples = 343\\nvalue = [1, 15, 23, 52, 94, 95, 63]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.646\\nsamples = 25\\nvalue = [1, 0, 1, 0, 5, 13, 5]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[6] <= 0.679\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 0, 0, 0, 1]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0, 0]'),\n",
              " Text(251.10000000000002, 135.9, 'X[5] <= 0.03\\ngini = 0.462\\nsamples = 13\\nvalue = [0, 0, 0, 0, 1, 9, 3]'),\n",
              " Text(209.25, 81.53999999999999, 'X[305] <= 0.5\\ngini = 0.298\\nsamples = 11\\nvalue = [0, 0, 0, 0, 0, 9, 2]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.18\\nsamples = 10\\nvalue = [0, 0, 0, 0, 0, 9, 1]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(292.95, 81.53999999999999, 'X[7] <= 50.0\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 0, 0, 1, 0, 1]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df3yWddnw8c8hkzZ+DKcbc+gYjhli5AS3e4gtEFvD8kclZvkjRcXq7u73TVF3z9Pdq56i++6J567splVoGJagGD/UMgrZLVYiNvqBsoYOQURLpUWDcnA8f3zP0YSNXde18zq/53ldx/v14uWLsV3n4blzx47re37P4xBVxRhjTDRO8B2AMcbkE0u6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgTIUu6xhgToQLfAZjcV1RUtPfgwYPlvuNIRWFh4fMHDhw41XccJneJqvqOweQ4EdGkXGcigqqK7zhM7rJK18TSmjVrKCkpYfz48bS1tfHUU08xceJETjvtNA4ePEhFRQUdHR3U1tbS09NDWVkZS5YsYd68edx6660sWLCAYcOG+f7fMOYYtqZrYumyyy6jsrKSdevWcdJJJ3HWWWdRUlJCbW0tBw8epLS0lJNPPpknnniCMWPGsH79el5++WXa2tq45JJLLOGa2LLlBZN1mSwvtLS0UFlZyciRI9m3bx/l5eWsXbuW5uZmNm3aRHV1NU1NTXR3d1NQUMCIESNYvnw5AFOmTKGnp4dZs2ZlEqstL5issqRrss7WdI35B1vTNZFYsWIFNTU17Nq1i9LSUrq6uti6dSsLFy6ks7OT4uJi2tvbqaiooK2tjRkzZnD48GHa2trYsmUL8+fPp6CggHXr1lFWVsbkyZOpqqpi0aJFNDY2cujQIRoaGrj//vuprq5mz5497Nq1i+bmZqqqqli2bBmjR4+mqamJ1tZW6uvr6enp4Q9/+APbtm1j8uTJzJw50/dpMnnAKl2TdbZlzJh/sBtpJusOHDhwqqpKqn+A1wObgQ1ATZpfezJwG7ATmJPO16qqWMI12WaVrokNERkOfBr4QPDf72S6GCwibwZagI3AR1X1pdACNWYIrNI1sSAiDcDjwDTgXFX99lDuvqnqg8AUYB/wOxGZKyJ2g8x4Z5Wu8UpERgKfB64GPgysCHurg4jMAL4LPAF8QFWfC/P1jUmHVbrGGxGZDfwGGAtMUdW7srG3TFUfAaYC24CtIjLPql7ji1W6JnIichLwn0Az8H5VvS/CY5+Lq3pfAm5R1aejOrYxYJWuiZiIXAb8DujBVbeRJVwAVW0DGoD1wGYR+ZCI2DPDJjJW6ZpIiMhY4GvAecDNqrrRc0iIyGuB7+AeErpZVbd5DsnkAat0TVaJcy3wW9ze2XPikHABVLUdmAXcAWwUkc+IyIl+ozK5zipdkzUiUgksASqBG1X1Mc8hDUhExuNiPQ0X6xbPIZkcZZWuCZ2InCAi78ftu/0FUBfnhAugqs8Ab8Xd4LtfRL4sIkWewzI5yCpdEyoRORO3TjocuCmJ66TB+vPXcdvMblbVVs8hmRxila4JhYgUiMgncJXtKuANSUy4AKr6gqpeBXwCuFNEvikixb7jMrnBkq4ZMhGpBX4FNAH1qvpfqnrIc1hDpqo/wj1KfCLuUeK3eA7J5ABbXjAZE5HXAJ8B3gssBG5LTLfyNInIRbgGOr8APqKqf/Ickkkoq3RNRkTkfODXuErwXFVdmqsJF0BVfwacA7wA/FZErrJHiU0mrNI1aRGRUcAXgKuADwF353Ky7Y+ITMc9StyBe4x5j+eQTIJYpWtSJiJNuIccSnCP8K7Mt4QLoKq/xLWgbMM10LnZql6TKqt0zaBEpAT4CvAm4L2q+mPPIcWGiJyDq3q7cA10dngOycScVbrmuETk7bgGNQdw1a0l3D5U9TfA+cD9wK9E5GPWQMccj1W6pl8iUo57QKAW94DA/3gOKfZEpAb3YEgR7sGQ33kOycSQVbrmVYIGNe/BNRffAdRawk2NqnYAs3HLDRtE5LPB3DdjjrBK1xwhIlXAt4ByXKX2uOeQEktETsc10KnCNdDZ7DkkExNW6ZreBjUfAB7DTc/9J0u4Q6Oqu4FLgS8Ca0XkKyIywnNYJgas0s1zIjIJtw55Aq66fdJzSDlHRMqA/4ebWHGzqj7kNyLjk1W6eUpEThSRhcDDwF1AoyXc7FDVP6rqNcBHgTtE5FsiMsZ3XMYPS7p5SESm4hrUXIhrUPMNVT3sOaycp6prcY9NK66BzqWeQzIe2PJCHhGRQuB/AzcDC4Bl+fhEWRyIyIXAt4FHgQ+r6h89h2QiYpVunhCRC3CPrb4WN6fse5Zw/VHVDbgGOs/iGuhcbY8S5werdHOciIzG3UG/Avigqt7jOSRzFBGpx+3t3YlroLPbc0gmi6zSzWEi0oxrUDMSeJ0l3HgK9vDWAZuBX4vIe0XEfjZzlFW6OUhETga+CszENah50HNIJkUi8jpc1XsAmB885WZyiP02zTEicgWuQc2fgddbwk0WVf09cAGwBviliPyriBR4DsuEyCrdHCEiFcA3gLNxG/A3eQ7JDJGIVON2OIzGPbjyW88hmRBYpZtwQYOaecBW4AlgqiXc3KCqT+F6GH8L+JmIfC6YS2cSzCrdBBORCbhhiafgKqE2rwGZrBGRccA3gTNx3+tfeg7JZMgq3QQSkWEi8iFcg5qfAQ2WcHNbMIft7cDngHtF5KsiMtJzWCYDlnQTRkQmA63AXGCGqn5ZVXs8h2UioM4K3KPEZbiHKi7yHJZJkyXdhAga1PwbLuEuB2aparvnsIwHqvqiql4H/Atwm4h8W0RO8h2XSY0l3QQQkWm4jfMXAOep6jetQY1R1ftxVe/fcQ10LvcckkmB3UiLMREpAj4LzAM+Diy3fgmmPyLyRlxf5MeBD6nqC55DMgOwSjemRKQR16DmDNxDDt+3hGsGoqqtuCGinbi13mutgU48WaUbMyJyMXAJcDnwL6r6I88hmYQRkfNwjxLvwVW/a1X1Fb9RmV5W6caIiFwD3I+rbqdYwjWZUNUtQD3uYZl7cAMyTUzYM93x0o5rVLNYVff5DsYkl6q+IiKfxfXg2O47HvMPtrxgjDERskp3AEVFRXsPHjxY7juOwRQWFj5/4MCBU33HYfzyfb3adZg6q3QHICKJ2CwgIqiq3aXOc76vV7sOU2eVbojWrFlDSUkJ48ePp62tjeeff55JkyZRUOBOc0VFBR0dHdTW1tLT00NZWRlLlixh3rx53HrrrSxYsIBhw4Z5/r8wuar3+hwzZgydnZ2MGTOGqVOn8tBDDzFr1ixeeOEFampqWL16NdXV1ezdu5fhw4fzzDPPcN111/kOP2dYpTuATCuHzs5OKioqeM1r/tGBr6enh507dzJx4sQwQwSswjBOqtdr3+vzySef5Kyzzgrr+HYdpsgq3ZA9+OCDTJo0ie7ubkaNGkVjYyOdnZ2MHTuWxx57jP3791NXV0drayubN2/mHe94B88++yxz5szxHbrJcS0tLUyaNIknnnjiyLXZ0dHB2LFjaW9vZ//+/VRXV/PII4/w3HPPcd555zFixAjq6up8h55TrNIdQCaVbktLC5WVlYwcOZJ9+/ZRXl7O2rVraW5uZtOmTVRXV9PU1ER3dzcFBQWMGDGC5cuXM2HCBCoqKnjppZe48MIL043TKgyT0vWa7vVZUlLCqlWrGDZsGPX19UyYMOF4x7frMEWWdAfg+8ZEquxiN+D/erXrMHW2vHAcK1asoKamhl27dlFaWkpXVxdbt25l4cKFdHZ2UlxcTHt7OxUVFbS1tTFjxgwOHz5MW1sbW7ZsYf78+RQUFLBu3TrKysqYPHkyVVVVLFq0iMbGRg4dOkRDQwPr16+ntLSUHTt20NTUdOQ1tm/fztixY5k4cSL19fXcfvvtTJw4kX379lFcXMzMmTN9nyITI6ler0VFRezZs4e6ujp27txJV1cXtbW1bNu2DVWloaGB1tZWhg8fzsyZM1m5ciXTp0+nsrKSxYsXM3fuXMaNG8fXvvY1pk2bZtdhmqzSHYDvfY+psv2RBvxfr3Ydps6SbhaISBXwK+BKVf2fAT7ng8CNuOkPB6KMz+SvoPPYcuBvwI39rUmIyOm4/s1Xq+qGiEPMeZZ0QxZMa30Y+KGq/t/jfJ4AdwLdqnpTVPGZ/CYiHwBuAc5X1e7jfN6bgGVAvao+G1V8+cCSbshE5JtAOTB3sDsbIjIKV1H8p6oujSI+k79EpAFYi3t31ZHC538GmANcaK0hw2NJN0RBa8bP4qqDP6f4NWcDG4Emm+hrskVESoEtwIdTbRkqIifgkvSTqvrxbMaXTyzphkREXgc8BFykqr9J82vfBXwBqLOWjiZsIjIMuA/4jap+Is2vPRmXrP9VVe/JRnz5xpJuCERkNG6Z4Euq+r0MX+PrQCXw9kRsEDaJEfTVnY0rCHoy+Po6XHP9N9gE6qGzpDtEwQ2xu4B9qnrLEF5nOG68+ipV/Y+w4jP5TUSagaW4d1HPDeF13osb+T5dVf8aVnz5yJLuEInIh4H3ABeo6sEhvtZ44FHgKlXdGEZ8Jn+FeT0FxUXvu7jr7d1Y5izpDoGIzADuxf32fzqk13wzcBtDrExMfsvGOycRGYHbf/4NVf1WGK+ZjyzpZkhExuJuMLxfVdeF/NpDWoMzJlv3CETktcAm4GJVfSys180nNg04A8Hd4DuBZWEn3MDngQPAF7Pw2ibHici7gYuBG8JeBghupL0fWBnsbDBpsko3AyLyBeB84M2qeihLx+jdV/kRVb03G8cwuSeqfd8i8lVgEnCpqh7O1nFykVW6aRKRtwLXA+/OVsIFUNU/AVcC3xKRM7N1HJM7gq2L9wCfjOBBm08CY4BPZfk4Occq3TSIyATcjYR3qOqmiI6Z0rPyJr8Fuwt+APw1ql4eInIabn/6e1R1fRTHzAWWdFMkIoW4RjbLVXVxhMcdtCuUMb661onIbNz1Wa+qu6M6bpJZ0k2RiCwBTgHeGXXiCxrjPAp8VVW/E+WxTfyJyHRgDe7d0A4Px/80cAkwS1X/HvXxk8aSbgpE5DrgM7jf5l2eYpiM23fZrKqP+4jBxI+IlOFuuH5QVVd7iuEEYDWwQ1U/4iOGJLGkOwgReT3wc2C2qv7WcyxX4baR1anqyz5jMf4FWxcfAH6tqp/0HEsJLvkvVNUVPmOJO0u6xyEixbgbBV9Q1Tt8xwMgIv8FnAG8zbbq5DcR+RwwE3hTHB6iEZHzgB8Djar6pO944sqS7gCCG1grgT+q6vt9x9MreLzzIWCNqi7yHI7xRETmAN/BvevZ6zueXiIyH/gI8E/WGKd/lnQHICIfBa7G/dYeUiObsNkMq/zWZwbfO1W11Xc8fQXFym24SePX2W6bY1nS7YeIvAG3ybxBVTs9h9MvEWnCdX2qU9U9vuMx0Qhm8P0PsEJVv+I7nv4EjXF+ASxR1f/2HU/cWNI9ioiU424I3KKq9/uO53hE5H8BzdgMq7wRzOA7FbgizlVk8BTlJuCtqrrZdzxxYo8B9yEiBbinem6Le8IN/B+gC7C13TwQzOBrAubFOeECqOofgPfhGuOc4jueOLFKtw8R+SJQD8zJZl+FMAUX9Bbg4zbDKnf1mcH3JlXd6jmclInIV4DX4Spe222DVbpHiMilwLW4m1OJSLgAqvoirjHOkqDXqckxfRrZLEhSwg18ChiFe7jIYJUuACJSjVv4f5uq/sJ3PJkQkffj+pxOt8Y4uaPPDL4/q+p83/FkQkTGAY/h+vs+6Dse3/I+6QaNbDbhGpL/l+94MhX8cN4BHCILzauNH8EMvutxjWxitXUxHSIyC/gh7lH6XZ7D8cqSrkgLri/ou5KeqERkJG7/5tdUtcV3PGZoghl8P8K9e3nKdzxDJSILgbcBb8znxjh5nXRF5HrcmlO9qv7FdzxhEJFJuBaUc1R1i+94TGb6zOD7Z1Vd6zueMASNce4Fdqrqh3zH40veJl0ROQf4Ga4d3e99xxMmEZkL/AfuwYmXfMdj0hM0svkJ8Kiqftp3PGESkZNwv0z+TVV/6DseH/Iy6YrIGNzC/r+r6nLf8WSDiCwGzgQus606ySIinwcuwM3g897IJmwiMhV4ELfM8ITveKKWd0k3uOF0N/C8qv6z73iyRUROxO3rvE9VbapwQojIW4AW4DxVfd53PNkiIjcBH8c1xtnvO54o5WPS/ThwFa6Rzd98x5NNwQyrx4BrVfVnvuMxx9dnBt8Vqvqw32iyT0SWAoXANUm/iZ2OvEq6ItKIq3L/SVV3+o4nCiJyEfB93Prus77jMf0LGtk8DPxAVb/qO54oiEgRbn/8t1X1Vt/xRCVvkq6InIqr+uar6gO+44mSiPwbcDHWGCe2ROS/gTLgyryq+kRqgEeAS1X1V77jiUJePAbcp5HNd/Mt4Qa+BOwDvuw7EHOsYAbfReThtGdV7QBuAVaISKnveKKQF5WuiCwCpgJvSVJfhTCJyMm4rTqfUNWVvuMxTpxm8PkkIv8BnINrjJPTP6M5X+mKyGW4CRDX5Po383iC/bpXAt8MHqAwngUz+O7GdYjL24Qb+DRQRB40xsnpSldEJuIW6i9T1V/6jicOROQW4EO4qRg2w8qTPjP4/qSq7/MdTxyISAXuvsuNqvoT3/FkS84m3eDO6CPAUlX9uu944iL4Yb8d9y7nPfm2hhgXwQy+a4A3JLmRTdhE5I3ACtwOo2d8x5MNOZl0g/XLp3GzpC61xPJqwQyr3wHDVfV03/HkGxFZC8wCXh/XGXw+BaPlP4brH7LJdzxhy9U13elAMXCHJdxjBf12VwKnBU+umWg1Ax1AXuwVz8BKXOPza30Hkg05WemCexttCff47Bz5Yed9cMEyGLl4nnI26RpjTBzl6vKCMcbEUkHUBywqKtp78ODB8qiPm67CwsLnDxw4cKrvODLh+xwn+dz1x+f5tHMZrjicz8iXF5KynCUiqKr4jiMTvs9xks9df3yeTzuXoR/f+/mMvNLNxJo1aygpKWH8+PG0tbWxa9cuamtrOeEEtzpSUVFBR0cHtbW19PT0UFZWxpIlS5g3bx633norCxYsYNiwYZ7/L+Kj93wWFxfz9NNPU1JSwtSpU3nooYeYNWsWL7zwAjU1NaxevZrq6mra29s588wz2b17N9u3b+fmm29m9OjRvv83YqH3XFZVVbFx40YOHDhAeXk5p59+OgcPHrRrMwO957S2tpaHH36YkSNH9nt9LlmyhLq6Ovbv309JSQl79uzh4osv9h3+oBJT6X7xi1+kvr6enp4eRo0aRWNjI08++SQHDx6kp6eH/fv3U1dXR2trK5s3b2b27NmUlJQwZcqUTOP0/hsxU6mc477n88UXX+Taa6+lo6ODsWPH0t7ezv79+6mpqWHDhg2MGDGCE088kdNPP51p06alcvzEnrv+DHY+Ozs7ue+++5gyZQrd3d2MGjWK888/n40bN1JfX3/kfJ5xxhm0tbXx1FNPUV1dzejRo5k9e/Zgx86rc9mr7zndvn07kydPprGx8Zhr9OSTT6azs5PLLrss1eN7P5+JSLotLS1UVlYycuRI9u3bR3l5OWvXrqW5uZlNmzZRXV1NU1MT3d3dFBQUMGLECJYvX05hYSETJ07kpZde4vLLL083Tu/fnEylco7TPadFRUWsWrWKG264IZXjJ/bc9Wew85nuuSwpKWHVqlUMGzaMSy+9lMLCwuMdO6/OJaR/PocPH866deu47rrrUjm+9/OZiKTrQxy+OZnyfY6TfO76Y2u64bFr09Oa7ooVK6ipqWHXrl2UlpbS1dXF1q1bWbhwIZ2dnRQXF9Pe3k5FRQVtbW3MmDGDw4cP09bWxpYtW5g/fz4FBQWsW7eOESNGUFdXR1VVFYsWLaKxsZFDhw7R0NDA+vXrKS0tZceOHTQ1NR15je3btzN27FgmTpxIfX09t99++5GK+KSTTmLmzJk+TkuoUj3HRUVF7Nmzh7q6Onbu3ElXVxe1tbV0dnaye/du5syZQ2trK8OHD2fmzJmsXr2acePGUV9fT0tLC83NzVRVVbFs2TKqqqpy4tz15/HHH8/4XG7btg1VpaGhYcBzuXjxYubOnUt5eTlLly5l8uTJOXsuh3ptDnQ+V65cyfTp06msrIz1tRl5pet7y0iq4rC1JFO+z3GSz11/bMtYeOzaTPATaUFTjJNU9cPB3z8FnKGqt/iNLJlE5HHgk6r60+DvjwBfUtW1fiNLHhEZD/waOF1VD4hIOfAkMF5V/+I3uuQRkfcBF6nqlcHfr8eNNbrEb2SZSeQTaSIyDJgHLO3z4e8BV4rISD9RJZeITAVOAfpODP4ucJOfiBLvBuCHqnoAIBil/hDwTo8xJdlNuOux193AjGDadeIkMuni5km9oKpbez+gqnuATcBcb1El143Abap6uM/HVgCzgoGeJkUicgLHFgQEf78x+oiSTUTOAU4Fftr7saD5/t3Ae3zFNRRJTbpH/+brZdVZmkSkEHg3cFvfjwdvg1cBg+/DMX1dCPwZePyojz8AnCEik6MPKdFuBG7vZ9TWd4Ebe7uRJUnikq6InILrR/qDfv75PmCSiLw22qgS7W3Ar1W1v96uS0nohe3RjbhpJa+6WaKqPcAyXBVsUiAir8FN17itn39+FPg70BhpUCFIXNLFfRPWqeq+o/9BVf8O3IFd2OkY6F0DuOWaE4DzowsnuUSkBHgrsHyAT1kKvMcax6fsMuC3qvrU0f8Q/FJL5DvbRCXdoOK6iWPXy/paClwvIonoK+GTiEzAjab/UX//HlzYthaZuncDP1HVF/v7R1VtB/4AvCXSqJLrRo7/s/594PJgqnJiJCrpAtOA0bg7wf1S1W24MShzIoopyW4AfjDIYMRlwBUiMiqakBLteO8aeiWyOouaiFQCDcA9A32Oqr6A23HzrqjiCkPSkm5/d9n7Y9XZII5zl/1VVPU53IDPK6OIK6lE5FygjFdvu+vP3UBjMG7cDOx64K7ebXfHkbif9cQk3WCk+rtw48MHcxcwO9iUbvp3EfCiqv46hc+16mxwvQXB0XfZX0VV95Pg7U5RCAqCGxn8XQPAT4BKEXlddqMKT2KSLvB2YLOq7hrsE1W1C7dOmZPTREMy2HpZX/cDNSIyKYvxJFaw7e5qUisIwHaFDGYmsB/YMtgnBrtCvkeCqt0kJd1U1sv6+i5wk13YxxKRk4GLGfgu+6uo6iu4td3EXNgRuxxoU9WnU/z8XwKHgAuyF1Ki3QR8N412ZEuBa0VkeBZjCk0ikq6InAGcA6xJ48sexnVRa8hKUMl2NXC/qr6cxtfYdqeBpfOuoe92J/sldhQROQm4BLczISWq2gE8EXxd7CUi6eJu+CxX1b+l+gV9tjvZWuSxBtt2dwxVfRJ4Clchm4CIVAF1wL1pfukdwNtFxOYevdq7gQcH2nZ3HIn5WY990g2a29xAeksLvb4HzLXtTv8gItOAEuDnGXy53VA71g30aW6TqmC70wbgqmwElWDpLiP2uhs4PwlNcGKfdIE3Ac+r6m/T/cJgu9PDWBOcvlLddteflcAbrQmO02fbXSZJAhK43SmbRKQWGAusT/drVbUbd31eH3ZcYUtC0s30N18vq84Cwba7d5P6XfZX6dMEx7Y7ObOBl1X16OY2qfoxMMGa4BwxUHObVPU2wYl1Xot1cCJSCrwZ+OEQXuY+4ExrggO45jZbBmhukyrb7vQPad1AO1oStztlS9DcJp1td/3ZDBwk5k1wYp10cc1t1vbX3CZVwXanO7ALG4b+rgHgkeC/M4b4OokWNLd5CyluuzuOpcB1tiuEy4Hf9NfcJlVJaYIT26SbYnObVPVud8rbJjhBc5tzgdVDeR1rgnPE1cCPVfWlobyIqv4BaMd1J8tnQ3rX0Mf3gctEZEwIr5UVsU26wHnASGDjUF9IVZ8AOsnv7U7zGLy5TaqWAe/I8+1OYbxr6BX76iybguY29bj7BUOiqn/E3YiLbROcOCfdodxl70/eVmd9ZsqFkiRUdS/QSp42wRlgptxQ3A1cICLjQnq9pLmB1JrbpCrWP+uxTLrBXfarGNqi+tHuAi7M0yY4FwF/VNW2EF8zn6uzUAuCpM/8Goo0m9uk6ifAaSIyJcTXDE0sky7wDuBRVd0d1gsG253uJT9nfoW1XtbXA0C1iJwV8uvGWp+ZcreH/NL5uitkFtDFsTPlMhZsOYvtrpC4Jt0w18v6yrsmOMFMuTnAnWG+bh43wemdKdcZ8uv+CngFeEPIrxt36Ta3SdVtxLQJTuySrohMBKYAa7Pw8vk48+sa4L40m9ukKh+b4IT9VhjIz14hKcyUy1jQBGcbcGnYrz1UsUu6uEX1tJrbpCrftjuFvO3uGKq6HeggT2Z+Bc1tpjHATLkQ3AG8LWkzv4bguDPlQhDL+w6xSrp9mttkJUkE8mnm1zSgGNdYJVtieWFnSZjb7o4RNMH5OfnTBCdby4i97gGmi8jpWTxG2mKVdIEm4LlMmtukKs9mfoW97a4/K8mDmV+pzpQLQV702U1jplzGgiY4K4hZE5y4Jd2svRU+Ss5XZ2nOlMtYMPPrHnJ/u1M6M+WG4ifAeBE5O8vH8S2lmXIh6N0VEptcF5tAguY2TcAPIjhcPsz8ejvwmKo+E8Gx8mG7Uza23R0jH5rgZDBTbig2A93AGyM4Vkpik3RxQyTXqOqfs32gPNnulO31sr5+ARwmR2d+pTtTLgS9TXBit90pJOnOlMtYHEcjxSLpZvsu+wBydruTiFTjZsoNqblNqpLS3WkIMpkpl7Fgu9OTJGTmVwaiLAggZk1wYpF0cTOmigihuU2qcnzm1w3AndnYdnccuTzzK+qCAGJWnYUl2HZ3HtnbdncMVf0T8FNi0gQnLkn3JtyiethPpQwm56qzPs1tIk0Sqvo8OTjzK6F37vsAAAYhSURBVGhuk+lMuaG4B5iRhJlfaboBt+0urOY2qYrNgyfek66IjADeibt5ELVcnPnVO1Nuq4dj5+KDJ70FQTa33R0jaIKzkhzaFRLhtrv+PAiME5HXezj2q3hPusAVwC/DbG6Tqhyd+RX1ellfD5BDM7+GOlMuBLm2K2SoM+UyFmxNu50YFAVxSLpZeZY9DTlzYfeZKRfFtrtjBNudcmlXSBgz5YbiUeBvxHzmVxoi2XZ3HL1NcF7jMQa/STdobvM6stPcJlW5NPPrGmDdUGbKhSCXdoX4fNeQU01wQpwplzFV3QH8Ds9NcHxXuvOA76vq330FkCtNcDxtuzuGqraTAzO/wpopF4I7gMtzoAlOKDPlQuD95rm3pBtRc5tU5cLMr/OAUcBDnuOAGFzYIZiH23aXleY2qQpmfv2MmGx3GgKv7xr6WAU0BHPZvPBZ6TYDz6rq7zzGAByZ+bURt4siqW4ClkZ9l30AK4E3JHXmV9gz5UKQ6F9iWZgpl7GgCc5deGyC4yXpikgZ8O/AD30cfwB3AgtE5AzfgaRLRGbj1nOX+Y4Fjmx3ug/4RpwajaThS0CXp213/XkQtyvko74DSVewJfQruMGTcSgIwP2cfEBEan0c3NcPxLm4kct/8XT8/rwMTCKZj14uBEYD2e7YlI4TcE13knhDbQEQpx6sh4CxwOd8B5KBctxWsVd8B9LHX4FTgfk+Di7RPwR2ZP/jzar69cgPfhwichPu7v/zvmNJh4g0AGNU9UHfsfQSkQLgg6q62Hcs6RKRG3G9Fvb6jqWXiLwWOFdVV/iOJR3BDd6PAV/18MTpgETknbimO+2RHztG58EYY3JeEtfbjDEmuVT1uH8KCwv3AhrXP4WFhXvjGnN/scUt1lRitDhzJ0aL01+cvX8GXV4QkbSXYlpaWpg0aRLd3d2MGjWKxsZGOjo6GDt2LO3t7ezfv5+6ujpaW1vZvHkz5557LpWVlUybNi2t4wTxoapy1MdSijmVOE855RR27NjB3r17qa6uZsyYMTQ0NGQcWz+fE1qsJSUl7Nmzh4svTr1bZSox5lqcqcQ4bdo0NmzYQFtbGx/72McYPXrwLdxhn8tUY033fFqcfuI88vnZSLpRGkrSzbYwk262ZOPCzoYkxJmEGIPjW5whSjfpFoQdQEtLC5WVlYwcOZJ9+/ZRXl7O2rVraW5uZtOmTVRXV9PU1ER3dzcFBQWMGDGC5cuXU1ZWRmlpKfv27ePyyy8PO6whxzl8+HDWrVvHX//6V+bOnUtpaWnWY8w01pKSElatWsW73hXtQ0yZfu/f9773xTbG3nNZVFTE2WefzZlnnhnrOOP+Pbc4U6x077rrLmpqati1axelpaV0dXWxdetWFi5cSGdnJ8XFxbS3t3P22WezYcMGZsyYweHDh2lra2PLli3Mnz+fgoIC1q1bR2FhIRMmTKC+vp5FixbR2NjIoUOHaGhoYP369ZSWlvL0009z0UUXsXv3bp555hl+//vfM3/+fF555RUeeOABiouLOeeccxgzZgwVFRX9VrqZxLxz5066urqora3lmWeeYdiwYUyaNInW1laGDx/OzJkzWbJkCVdccQVlZWXceeedTJo0id27dzNnzhzuvfdepk6dyssvv8z06dNTrnRTjbWoqIg9e/ZQV1f3qli3bduGqtLQ0PCqWFevXs24ceOor6+npaWF5uZmqqqqWLZsGVVVVcycOTOtamKocXZ2dh45V4PFWVFRwZIlS6itrY08zlTO5+LFi5k7dy6VlZVHzuesWbNiFWMcvudJj3PlypVMnz6dysrKIV+bR8R9kXqwP3YjLZqbABZnbsRocfqLs/eP7dM1xpgI2T5dY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJkCVdY4yJ0P8Hgo4MZhcVGzEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXavTHRkshrT"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y8QWC8Krslf7",
        "outputId": "142738d7-b47f-4535-e669-0a902d6e96b0"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'balanced_life',\n",
        "             'trauma',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "model_19 = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=1) \n",
        "# Using default parameters\n",
        "\n",
        "# Training model\n",
        "model_19.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model_19.predict(X_test) # Predicting labels for our test set using model\n",
        "print(y_pred)\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function\n",
        "\n",
        "tree.plot_tree(model_19)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 2 5\n",
            " 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00        12\n",
            "           3       0.00      0.00      0.00        20\n",
            "           4       0.00      0.00      0.00        39\n",
            "           5       0.29      0.98      0.44        47\n",
            "           6       1.00      0.05      0.10        38\n",
            "\n",
            "    accuracy                           0.29       166\n",
            "   macro avg       0.18      0.15      0.08       166\n",
            "weighted avg       0.31      0.29      0.15       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  3  0]\n",
            " [ 0  0  0  0  0  7  0]\n",
            " [ 0  0  0  0  0 12  0]\n",
            " [ 0  0  0  0  0 20  0]\n",
            " [ 0  0  0  0  0 39  0]\n",
            " [ 0  0  1  0  0 46  0]\n",
            " [ 0  0  2  0  0 34  2]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 190.26, 'X[265] <= 0.5\\ngini = 0.781\\nsamples = 385\\nvalue = [2, 15, 27, 52, 100, 117, 72]'),\n",
              " Text(83.7, 135.9, 'X[200] <= 0.5\\ngini = 0.784\\nsamples = 372\\nvalue = [2, 15, 27, 52, 99, 108, 69]'),\n",
              " Text(41.85, 81.53999999999999, 'X[230] <= 0.5\\ngini = 0.781\\nsamples = 368\\nvalue = [2, 15, 24, 52, 99, 108, 68]'),\n",
              " Text(20.925, 27.180000000000007, 'gini = 0.785\\nsamples = 343\\nvalue = [1, 15, 23, 52, 94, 95, 63]'),\n",
              " Text(62.775000000000006, 27.180000000000007, 'gini = 0.646\\nsamples = 25\\nvalue = [1, 0, 1, 0, 5, 13, 5]'),\n",
              " Text(125.55000000000001, 81.53999999999999, 'X[5] <= 0.457\\ngini = 0.375\\nsamples = 4\\nvalue = [0, 0, 3, 0, 0, 0, 1]'),\n",
              " Text(104.625, 27.180000000000007, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0, 0, 0]'),\n",
              " Text(146.475, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(251.10000000000002, 135.9, 'X[5] <= 0.03\\ngini = 0.462\\nsamples = 13\\nvalue = [0, 0, 0, 0, 1, 9, 3]'),\n",
              " Text(209.25, 81.53999999999999, 'X[234] <= 0.5\\ngini = 0.298\\nsamples = 11\\nvalue = [0, 0, 0, 0, 0, 9, 2]'),\n",
              " Text(188.32500000000002, 27.180000000000007, 'gini = 0.18\\nsamples = 10\\nvalue = [0, 0, 0, 0, 0, 9, 1]'),\n",
              " Text(230.175, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(292.95, 81.53999999999999, 'X[75] <= 0.5\\ngini = 0.5\\nsamples = 2\\nvalue = [0, 0, 0, 0, 1, 0, 1]'),\n",
              " Text(272.02500000000003, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 0, 0, 1]'),\n",
              " Text(313.875, 27.180000000000007, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1, 0, 0]')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9phtuJVowCG3"
      },
      "source": [
        "## Ensemble Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH17t6ahwD56"
      },
      "source": [
        "### Predict trauma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3290EIUjmXkQ"
      },
      "source": [
        "#### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auiAlHP90Vj1",
        "outputId": "9c06dbb3-b9e9-434b-e176-24b359606bb9"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_1a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_1a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_1a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.76      0.73       104\n",
            "           1       0.53      0.45      0.49        62\n",
            "\n",
            "    accuracy                           0.64       166\n",
            "   macro avg       0.61      0.61      0.61       166\n",
            "weighted avg       0.64      0.64      0.64       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[79 25]\n",
            " [34 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3DNSmjqmleW"
      },
      "source": [
        "#### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PW2N5w51MZm",
        "outputId": "25ffe159-edb8-469a-d8f8-6bff87c29a09"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_2a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_2a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_2a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.74      0.72       104\n",
            "           1       0.51      0.45      0.48        62\n",
            "\n",
            "    accuracy                           0.63       166\n",
            "   macro avg       0.60      0.60      0.60       166\n",
            "weighted avg       0.62      0.63      0.63       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[77 27]\n",
            " [34 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0VGr2F8mo2G"
      },
      "source": [
        "#### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps4_p_sj1hAd",
        "outputId": "34ccfec4-5b0c-4334-cc89-778dd178d314"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_3a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_3a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_3a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.74      0.72       104\n",
            "           1       0.51      0.45      0.48        62\n",
            "\n",
            "    accuracy                           0.63       166\n",
            "   macro avg       0.60      0.60      0.60       166\n",
            "weighted avg       0.62      0.63      0.63       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[77 27]\n",
            " [34 28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeHg06N4wID8"
      },
      "source": [
        "### Predict specific mental health indicators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2oRDz31qQwX"
      },
      "source": [
        "##### Life Enjoyment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InSuEEe-qnDg"
      },
      "source": [
        "###### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4Y7JUjb1_zG",
        "outputId": "de81b63c-3d12-4fa0-9aaa-536ba2c5f42b"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_4a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_4a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_4a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.25      0.27      0.26        11\n",
            "           2       0.11      0.04      0.05        28\n",
            "           3       0.25      0.31      0.28        48\n",
            "           4       0.20      0.22      0.21        36\n",
            "           5       0.08      0.12      0.09        26\n",
            "           6       0.20      0.08      0.12        12\n",
            "\n",
            "    accuracy                           0.19       166\n",
            "   macro avg       0.15      0.15      0.14       166\n",
            "weighted avg       0.18      0.19      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  1  0  2  2  0  0]\n",
            " [ 0  3  1  4  1  2  0]\n",
            " [ 0  3  1  9  5  9  1]\n",
            " [ 0  4  4 15 12 12  1]\n",
            " [ 0  0  1 17  8  9  1]\n",
            " [ 0  1  1  9 11  3  1]\n",
            " [ 0  0  1  5  2  3  1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abLFwtDYqpto"
      },
      "source": [
        "###### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2VZf_3g2ZJO",
        "outputId": "d539c27c-a3f9-4afc-fbe1-0b8e848227fa"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_5a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_5a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_5a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.23      0.27      0.25        11\n",
            "           2       0.11      0.04      0.05        28\n",
            "           3       0.25      0.31      0.28        48\n",
            "           4       0.20      0.22      0.21        36\n",
            "           5       0.05      0.08      0.06        26\n",
            "           6       0.20      0.08      0.12        12\n",
            "\n",
            "    accuracy                           0.18       166\n",
            "   macro avg       0.15      0.14      0.14       166\n",
            "weighted avg       0.17      0.18      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  1  0  2  2  0  0]\n",
            " [ 0  3  1  4  1  2  0]\n",
            " [ 0  3  1  9  5  9  1]\n",
            " [ 0  4  4 15 12 12  1]\n",
            " [ 0  0  1 17  8  9  1]\n",
            " [ 0  2  1  9 11  2  1]\n",
            " [ 0  0  1  5  2  3  1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlE3lzw7qzNk"
      },
      "source": [
        "###### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nGSGVJy2mJl",
        "outputId": "1653dc61-fbe3-4d00-f9f4-5c9e591959a9"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_6a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_6a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_6a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.23      0.27      0.25        11\n",
            "           2       0.11      0.04      0.05        28\n",
            "           3       0.25      0.31      0.28        48\n",
            "           4       0.20      0.22      0.21        36\n",
            "           5       0.05      0.08      0.06        26\n",
            "           6       0.20      0.08      0.12        12\n",
            "\n",
            "    accuracy                           0.18       166\n",
            "   macro avg       0.15      0.14      0.14       166\n",
            "weighted avg       0.17      0.18      0.17       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  1  0  2  2  0  0]\n",
            " [ 0  3  1  4  1  2  0]\n",
            " [ 0  3  1  9  5  9  1]\n",
            " [ 0  4  4 15 12 12  1]\n",
            " [ 0  0  1 17  8  9  1]\n",
            " [ 0  2  1  9 11  2  1]\n",
            " [ 0  0  1  5  2  3  1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjVqlloeqX4J"
      },
      "source": [
        "##### Resilience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftT-ooPoq8Jz"
      },
      "source": [
        "###### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwe_RApT26Dv",
        "outputId": "261fe26d-88aa-4f71-8989-64392e12421e"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_7a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_7a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_7a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.17      0.06      0.08        18\n",
            "           3       0.33      0.04      0.08        23\n",
            "           4       0.37      0.70      0.49        47\n",
            "           5       0.32      0.27      0.29        49\n",
            "           6       0.19      0.15      0.17        26\n",
            "\n",
            "    accuracy                           0.31       166\n",
            "   macro avg       0.20      0.17      0.16       166\n",
            "weighted avg       0.29      0.31      0.27       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  1  1  0]\n",
            " [ 0  0  1  0  9  5  3]\n",
            " [ 0  1  2  1 13  6  0]\n",
            " [ 0  1  1  0 33 10  2]\n",
            " [ 0  4  1  1 19 13 11]\n",
            " [ 0  0  1  1 14  6  4]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMVKwFTvrAMF"
      },
      "source": [
        "###### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CmMuJEh3JIZ",
        "outputId": "3464b483-cc9b-4aaf-fc44-ebcc5eab6b59"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_8a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_8a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_8a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.20      0.06      0.09        18\n",
            "           3       0.25      0.04      0.07        23\n",
            "           4       0.37      0.70      0.49        47\n",
            "           5       0.30      0.24      0.27        49\n",
            "           6       0.23      0.19      0.21        26\n",
            "\n",
            "    accuracy                           0.31       166\n",
            "   macro avg       0.19      0.18      0.16       166\n",
            "weighted avg       0.29      0.31      0.27       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  1  1  0]\n",
            " [ 0  0  1  0  9  5  3]\n",
            " [ 0  1  2  1 13  6  0]\n",
            " [ 0  1  1  0 33 10  2]\n",
            " [ 0  4  1  2 19 12 11]\n",
            " [ 0  0  0  1 14  6  5]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u__T405QrEdg"
      },
      "source": [
        "###### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTcEKg0c3W2l",
        "outputId": "b2fb6230-0d5c-41ed-c558-c7403a87435c"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_9a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_9a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_9a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.22      0.11      0.15        18\n",
            "           3       0.33      0.04      0.08        23\n",
            "           4       0.37      0.68      0.48        47\n",
            "           5       0.32      0.27      0.29        49\n",
            "           6       0.19      0.15      0.17        26\n",
            "\n",
            "    accuracy                           0.31       166\n",
            "   macro avg       0.21      0.18      0.17       166\n",
            "weighted avg       0.30      0.31      0.27       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  1  1  0]\n",
            " [ 0  0  2  0  9  4  3]\n",
            " [ 0  1  3  1 12  6  0]\n",
            " [ 0  1  2  0 32 10  2]\n",
            " [ 0  4  1  1 19 13 11]\n",
            " [ 0  0  1  1 13  7  4]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtX5ttvfqaa5"
      },
      "source": [
        "#### Balanced Life"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnLJhYpirLwV"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cZ6RPWG3oJj",
        "outputId": "39861b21-4851-4397-cd9d-8915d6e060c6"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_10a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_10a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_10a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        36\n",
            "           3       0.21      0.19      0.20        36\n",
            "           4       0.19      0.66      0.29        32\n",
            "           5       1.00      0.03      0.05        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.17       166\n",
            "   macro avg       0.20      0.13      0.08       166\n",
            "weighted avg       0.31      0.17      0.11       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  2  0  0  0  0]\n",
            " [ 0  0  1  2  3  0  0]\n",
            " [ 0  1  0 13 22  0  0]\n",
            " [ 0  2  1  7 24  0  2]\n",
            " [ 0  2  4  5 21  0  0]\n",
            " [ 0  0  2  4 31  1  0]\n",
            " [ 1  2  1  2 10  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnGDpoKurRcw"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm4uafdc36la",
        "outputId": "c010a4ab-07f5-4224-ea7d-5fdc2e6e8445"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_11a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_11a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_11a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.15      0.06      0.08        36\n",
            "           3       0.22      0.17      0.19        36\n",
            "           4       0.18      0.59      0.27        32\n",
            "           5       0.12      0.03      0.04        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.17       166\n",
            "   macro avg       0.10      0.12      0.08       166\n",
            "weighted avg       0.14      0.17      0.12       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  2  0  0  0  0]\n",
            " [ 0  0  1  2  3  0  0]\n",
            " [ 0  1  2  7 21  4  1]\n",
            " [ 0  2  1  6 23  2  2]\n",
            " [ 0  2  4  6 19  1  0]\n",
            " [ 0  0  2  4 31  1  0]\n",
            " [ 1  2  1  2 10  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9SR9tRMrZW7"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jp3UiQw4GNL",
        "outputId": "19d545bf-366f-4ffc-ef05-5ca5375fb2cb"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_12a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_12a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_12a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined functio"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        36\n",
            "           3       0.21      0.19      0.20        36\n",
            "           4       0.19      0.66      0.29        32\n",
            "           5       1.00      0.03      0.05        38\n",
            "           6       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.17       166\n",
            "   macro avg       0.20      0.13      0.08       166\n",
            "weighted avg       0.31      0.17      0.11       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  2  0  0  0  0]\n",
            " [ 0  0  1  2  3  0  0]\n",
            " [ 0  1  0 13 22  0  0]\n",
            " [ 0  2  1  7 24  0  2]\n",
            " [ 0  2  4  5 21  0  0]\n",
            " [ 0  0  2  4 31  1  0]\n",
            " [ 1  2  1  2 10  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGCzIKxJqfHe"
      },
      "source": [
        "#### Emotional Flexibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm0BsevSrjJ7"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE_Pezbn4avn",
        "outputId": "4def1dc3-fc35-4e99-e7f9-adac1442e259"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_13a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_13a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_13a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.27      0.11      0.15        28\n",
            "           3       0.18      0.25      0.21        24\n",
            "           4       0.32      0.39      0.35        38\n",
            "           5       0.29      0.50      0.36        36\n",
            "           6       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.25       166\n",
            "   macro avg       0.15      0.18      0.15       166\n",
            "weighted avg       0.21      0.25      0.22       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  1  1  3  0]\n",
            " [ 0  0  0  3  3  5  0]\n",
            " [ 1  0  3  5  6 10  3]\n",
            " [ 1  0  2  6  9  6  0]\n",
            " [ 0  0  2  7 15 13  1]\n",
            " [ 1  2  0  5  9 18  1]\n",
            " [ 1  0  4  7  4  8  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOCgO_dXrn2f"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR4i3k624vcQ",
        "outputId": "77d15389-2d44-4ef8-f55d-119d08f077fe"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_14a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_14a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_14a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.27      0.11      0.15        28\n",
            "           3       0.18      0.25      0.21        24\n",
            "           4       0.32      0.39      0.35        38\n",
            "           5       0.29      0.50      0.36        36\n",
            "           6       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.25       166\n",
            "   macro avg       0.15      0.18      0.15       166\n",
            "weighted avg       0.21      0.25      0.22       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  1  1  3  0]\n",
            " [ 0  0  0  3  3  5  0]\n",
            " [ 1  0  3  5  6 10  3]\n",
            " [ 1  0  2  6  9  6  0]\n",
            " [ 0  0  2  7 15 13  1]\n",
            " [ 1  2  0  5  9 18  1]\n",
            " [ 1  0  4  7  4  8  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_z8UBdArsIp"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlN63MtX46ib",
        "outputId": "945e1573-5d05-46e8-b232-ee81a80a0109"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_15a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_15a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_15a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.27      0.11      0.15        28\n",
            "           3       0.18      0.25      0.21        24\n",
            "           4       0.32      0.39      0.35        38\n",
            "           5       0.29      0.50      0.36        36\n",
            "           6       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.25       166\n",
            "   macro avg       0.15      0.18      0.15       166\n",
            "weighted avg       0.21      0.25      0.22       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  1  1  3  0]\n",
            " [ 0  0  0  3  3  5  0]\n",
            " [ 1  0  3  5  6 10  3]\n",
            " [ 1  0  2  6  9  6  0]\n",
            " [ 0  0  2  7 15 13  1]\n",
            " [ 1  2  0  5  9 18  1]\n",
            " [ 1  0  4  7  4  8  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STNSqkw1qiA6"
      },
      "source": [
        "#### Self Actualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmFanHUCrwoJ"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYb__PqD5LHK",
        "outputId": "2d043977-965c-43a5-d19c-1bdf7bfca205"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = StandardScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_16a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_16a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_16a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.11      0.08      0.10        12\n",
            "           3       0.00      0.00      0.00        20\n",
            "           4       0.53      0.23      0.32        39\n",
            "           5       0.23      0.34      0.28        47\n",
            "           6       0.13      0.18      0.16        38\n",
            "\n",
            "    accuracy                           0.20       166\n",
            "   macro avg       0.14      0.12      0.12       166\n",
            "weighted avg       0.23      0.20      0.20       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  1  2]\n",
            " [ 0  0  0  0  2  1  4]\n",
            " [ 0  2  1  1  1  4  3]\n",
            " [ 0  1  1  0  1 11  6]\n",
            " [ 0  3  1  1  9 16  9]\n",
            " [ 0  4  2  1  3 16 21]\n",
            " [ 0  4  4  2  1 20  7]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQBVokOsr0Aj"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpgzWBLv5i5C",
        "outputId": "1978c030-e64a-4af8-820f-d863cdfd8741"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = MinMaxScaler()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_17a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_17a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_17a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.12      0.08      0.10        12\n",
            "           3       0.00      0.00      0.00        20\n",
            "           4       0.41      0.23      0.30        39\n",
            "           5       0.25      0.34      0.29        47\n",
            "           6       0.13      0.18      0.16        38\n",
            "\n",
            "    accuracy                           0.20       166\n",
            "   macro avg       0.13      0.12      0.12       166\n",
            "weighted avg       0.21      0.20      0.19       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  1  2]\n",
            " [ 0  0  0  0  1  2  4]\n",
            " [ 0  2  1  1  2  3  3]\n",
            " [ 0  1  0  0  3 10  6]\n",
            " [ 0  3  1  1  9 16  9]\n",
            " [ 0  4  2  1  3 16 21]\n",
            " [ 0  4  4  2  4 17  7]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvKswiR9r3Vl"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9gwuKKb5194",
        "outputId": "d10a84cf-7678-4f6b-cc1c-d23e46c2d860"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# define a new scaler: \n",
        "x_scaler = FunctionTransformer()\n",
        "\n",
        "# fit the normalization on the training set: \n",
        "x_scaler.fit(X_train)\n",
        "\n",
        "# then create new and normalized training/test sets: \n",
        "X_train_norm = x_scaler.transform(X_train)\n",
        "X_test_norm = x_scaler.transform(X_test)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model_18a = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1) # Define the model with parameters\n",
        "model_18a.fit(X_train_norm, y_train) # Training the model\n",
        "\n",
        "y_pred = model_18a.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
        "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.11      0.08      0.10        12\n",
            "           3       0.00      0.00      0.00        20\n",
            "           4       0.47      0.23      0.31        39\n",
            "           5       0.21      0.30      0.25        47\n",
            "           6       0.13      0.18      0.16        38\n",
            "\n",
            "    accuracy                           0.19       166\n",
            "   macro avg       0.13      0.11      0.12       166\n",
            "weighted avg       0.21      0.19      0.19       166\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 0  0  0  0  0  1  2]\n",
            " [ 0  0  0  0  2  1  4]\n",
            " [ 0  2  1  1  0  5  3]\n",
            " [ 0  1  1  0  1 11  6]\n",
            " [ 0  3  1  1  9 16  9]\n",
            " [ 0  4  2  1  5 14 21]\n",
            " [ 0  4  4  3  2 18  7]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5_qAP1wK_K"
      },
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2eYXI3Od3xF"
      },
      "source": [
        "### Predict total health score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuOg0hu5d9Cw"
      },
      "source": [
        "#### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXEl28fBeHeJ",
        "outputId": "01ec7187-80b0-4413-ca4b-122bf478c0d2"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39.85556805447666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zouyrjad_hs"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B-6E6HPePfI",
        "outputId": "a4cb8b80-4d5a-47c5-c74c-d88d834cc15a"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', PCA()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28.89091183149181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz30BpQ1eByk"
      },
      "source": [
        "#### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlm8D8TCeW2t",
        "outputId": "fce342df-2593-48ee-c3af-5470a083dd0c"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28.872433480697115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUn_elpheEN4"
      },
      "source": [
        "#### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbSwPvguegom",
        "outputId": "89eee76a-35a0-4d07-8cae-49845fa5f189"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28.890911831481297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsw8fLXQwNRT"
      },
      "source": [
        "### Predict trauma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uE10JbSgXPT"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5qYPEYPgapO",
        "outputId": "29e9e354-91bd-4e1a-caf9-edeaba006be4"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3877051481287812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjKrMK9ugB-G"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gluhSKFLfeCu",
        "outputId": "4fb238f5-30a4-4934-a10b-722c82f8906b"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2526202314998527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgJs6fwhgmae"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivxdscvWgrgc",
        "outputId": "4f1ac4f1-7460-4e5d-da8d-ab0d669d1c82"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25298568391452236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwHERP2Ygo7F"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpnVlJdlgxIY",
        "outputId": "4c17601a-8ce4-49f5-daa2-89a14a24b59f"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25262023149889656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSH6oMRtwPS0"
      },
      "source": [
        "### Preduct specific mental health indicators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c43bHatXnoeY"
      },
      "source": [
        "#### Life Enjoyment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmvQcSeYoUc3"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM-SEe16opkW",
        "outputId": "fa594bc9-afbe-4447-abe3-f569f6598730"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.350276149577869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1APRtPnooYGN"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL4tlraioqle",
        "outputId": "77624ba5-a9ae-48ca-fc2f-bfc009254dd3"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1961130755086984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJP7b0McodIL"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XadmIcSVorkP",
        "outputId": "3b84170f-bf01-41ac-d2e1-3a5b9df3743e"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1950032871191465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiGZAXBsof4G"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61O1QL7xoswZ",
        "outputId": "e794d99e-cef4-40b2-f909-07debb1166a8"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1961130755026437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjQ5L3cvnuI0"
      },
      "source": [
        "#### Resilience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPCJC9UToujh"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJY3_xtppBni",
        "outputId": "99fd07c5-f883-4c8b-aae2-1bcb623bd1e4"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5483162995143633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7To24j5wozwO"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-82JaiUNpDGi",
        "outputId": "fc687072-0ece-41ba-cd43-7faf9e437e30"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7876853308083973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnzFOkrOo5la"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G0Lx03lpEfN",
        "outputId": "f7ac41a4-7b95-435e-d45c-a2092c313b98"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7880077955638627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH7yOUpko9L6"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmWJcxVfpF9P",
        "outputId": "7f790085-a395-4bcc-a4d8-993bcfd4da8e"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.787685330806692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzGWOje3nw_J"
      },
      "source": [
        "#### Balanced Life"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Y9EVBopILk"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpu74uQ1qDud",
        "outputId": "7db07443-1b4a-467f-ce35-d9ca16b36dd9"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.718031491794366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZP2TthNpMrV"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eby3QJkNqCz7",
        "outputId": "252e1dae-fd14-4040-8632-e363f10fc471"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2844670463159575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXywmMmjpPN0"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyOMzOQ7qB2B",
        "outputId": "7dcd65bb-f0de-4c56-903d-1eb88e23c2d3"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.284386053081449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb49L5pnpVFd"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q78Tu1L0qAJ4",
        "outputId": "85567d4c-ca89-40d1-ed11-f0f179878459"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['balanced_life', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2844670463106755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk29sjcun2CU"
      },
      "source": [
        "#### Emotional Flexibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TahI5-hpax6"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoLV24W2p-sH",
        "outputId": "39afa8a4-9771-4e8d-cbd2-487810eaa4bf"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.080889251936879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoOzR1bWpdIT"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUTJFJacp88q",
        "outputId": "f2cb03db-bf23-4e14-ca1a-0b56acd3062e"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8162087725502647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZGkwuqDpfMV"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7vFyl60p74y",
        "outputId": "1caedad0-a382-4ae7-c8a4-4475d7a8f688"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8094069935216024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y7J4SeKpkVl"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqK1bj_8p6ew",
        "outputId": "a3309da8-24d0-4b8c-8af0-dfc8b1cbf3ee"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['emotional_flex', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.816208772549627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnPJRoC0n_gB"
      },
      "source": [
        "#### Self Actualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OFb-mqZppjM"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaHhQg1wp5Bj",
        "outputId": "ac0b9acb-bdd5-4121-a4b1-65fb9ced9adc"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.170529757744025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2caG2KVjpsTh"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vaiZ8PSp4AB",
        "outputId": "8ade0e1d-c9d1-4968-ebe3-03405033b943"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4778308064750285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgVHzQ77puii"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH5cQkPSp2-Q",
        "outputId": "bbec4dee-c4c8-498c-e7b9-1a793cb00fef"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.478309942976805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnEA3bDqpyJW"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2bkajoMp15G",
        "outputId": "71d4672c-7491-4b74-b736-ad52e6f14416"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['self_actualization', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Ridge())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4778308064770473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLDhXZiTwRhV"
      },
      "source": [
        "## Lasso Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6rO4wGCep5F"
      },
      "source": [
        "### Predict total health score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQFkbzvSevBP"
      },
      "source": [
        "#### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BqaSx6bexAo",
        "outputId": "46a5b0f3-4ed8-4b2d-a26d-6c447a558c12"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.35078753197983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvYVoQBSe1VP"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSl78v1OfKo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a914245-b0a9-450e-88b1-7ec12284806c"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', PCA()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.355032908426953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwYUGWE8e3gY"
      },
      "source": [
        "#### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIcxgCRXe80K",
        "outputId": "55d0bf7d-b034-4568-a3d3-9f6674acaba3"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.35078753197983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_LKVqX5fBOn"
      },
      "source": [
        "#### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDsBpHstfECt",
        "outputId": "8d23785c-b8bf-4483-ed3a-37a85cd895ea"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', \n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health', # y\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['total_health'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.35347919891419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoTRV9giwTit"
      },
      "source": [
        "### Predict trauma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wIds6hrg8PA"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJjMX2Ng4c3",
        "outputId": "bfabd6f1-b883-434e-850b-5db8a4762880"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23456784804930633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwg_ADdAg-cv"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLbPcN4ghHH1",
        "outputId": "c5154e5e-85e4-45d1-9724-e857a3b7fabc"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23456784804930633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCb3sXSEhArh"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXisYXAyhTdl",
        "outputId": "8bbf5667-a43d-4b77-d89a-1fd3a2600412"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23456784804930633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3r9yv3hhDWz"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGRO8Mb9hZp7",
        "outputId": "8c9e7300-0797-43e6-a353-4a3bc9ca31fc"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['trauma', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'life_enjoyment', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex', \n",
        "             'self_actualization',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['trauma'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23456784804930633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFagspBKwU8y"
      },
      "source": [
        "### Predict specific mental health indicators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V18tRLXSi9D0"
      },
      "source": [
        "#### Life Enjoyment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4QHLyg0j1-E"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7IQkLNQkCgZ",
        "outputId": "9bd0ea0d-50bd-4a88-d2e2-b6c7d42ab8d3"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0727004899340993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LEc4_1cj4RA"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf6nRSy6kFIK",
        "outputId": "7933ce67-aa8f-44a4-b3c8-8a39937bf839"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.072020319766609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJaTk3wYj6GU"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMY4N-6OkGUw",
        "outputId": "5892340f-49fe-4a94-f52c-a5bc61f5ad66"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0727004899340993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pdous_oj8Yu"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObQyz1bxkHtg",
        "outputId": "04793863-f680-40e6-e0a1-552f805a5886"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['life_enjoyment', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'resilience', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['life_enjoyment'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0720403917938226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn9kdEmKjpfa"
      },
      "source": [
        "#### Resilience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LFAt7ddkJbC"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IADd_UBik0GH",
        "outputId": "cf3b2f76-bbd8-47ec-90a5-2058e8c4a7be"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7657318428715707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaPcAkrRkNO5"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro3JdzU2k2Ao",
        "outputId": "cc36df69-921a-4f0d-85d3-e4315c2cc179"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.76584740476252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCf0xxtekPT5"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQzoWrzrk25p",
        "outputId": "9811cd07-3cad-4535-cec6-693fe3690443"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7657318428715707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN6oG9xIkScR"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZNKY-Clk39M",
        "outputId": "6360083a-d76f-4eb7-b961-36867d0aca2c"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['resilience'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7652419457632227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwuHdwecjs3Z"
      },
      "source": [
        "#### Balanced Life"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-Lu3Tj3kWGo"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm0MBb8JkU5X",
        "outputId": "cad7bac8-3be2-4a7c-f877-a0a098ce0127"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.072986159514089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrGb3GdskYxh"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TDsYiIgkq3q",
        "outputId": "887e8970-9775-481b-e4cd-090cfd2d2b14"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0657768032801163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeQvGKahkhw1"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0tsPQ4hkrr_",
        "outputId": "6045eb29-1916-499d-81b4-217c6ef0cf7b"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.072986159514089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxB4nRfQkmPO"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RxWZIelktmV",
        "outputId": "a863c8fb-e158-47a2-96d0-3f55a1faa334"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['balanced_life'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0643974521508404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLbxQvK0jv9T"
      },
      "source": [
        "#### Emotional Flexibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-LIPNqbk6mR"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuHQyY1Zkppk",
        "outputId": "1c018765-7d0f-48e8-92ee-7b915d871093"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6220736140717364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OveaYSPblbnl"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUoVN2h5mAp4",
        "outputId": "f4c240ca-d304-4d19-e19e-26b768f45851"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pcs', PCA()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.622386234530986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGnx8AfKleOD"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghqDWoKKl-rD",
        "outputId": "a96eb241-e9fe-4226-af67-c5b18f8d9854"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6220736140717364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOzMIfflhvK"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj_U89hLCRAw",
        "outputId": "830f3128-9b20-4efd-957f-02c935ca5bc7"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['emotional_flex'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.622462491110615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUWpIE8Ljyn_"
      },
      "source": [
        "#### Self Actualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHCvk5selmYh"
      },
      "source": [
        "##### Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEzKOIoTmDgh",
        "outputId": "4b19ab42-ae2d-4a76-b163-ddfbf5d01278"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2004675405958465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61fKwP10lpSN"
      },
      "source": [
        "##### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd-C33UumFr9",
        "outputId": "9b966ae2-6e39-4a5e-cd3b-29de48d09c7c"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('pca', PCA()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1967967245261284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWClosMPlrrF"
      },
      "source": [
        "##### MinMax Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03juuRCfmG77",
        "outputId": "ca36864a-e33b-4f96-f98f-804bde602949"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2004675405958465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUyFGFtluDa"
      },
      "source": [
        "##### Function Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez4iv0MxmH2Q",
        "outputId": "1e942c82-b352-4bed-fd12-b614b1e839ce"
      },
      "source": [
        "# training and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# data = pd.get_dummies(data, drop_first=True)\n",
        "# We split the data up into a test set and a training set, 30 - 70 %\n",
        "# train_test_split\n",
        "# First argument: x data is all data without class column\n",
        "# Second argument:  this is the class label column\n",
        "# Random state = 0: ensures the train and test splitting is deterministic. \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop(['resilience', # y\n",
        "             'gender', \n",
        "             'age', \n",
        "             'amount_music',\n",
        "             'trauma', \n",
        "             'self_actualization', \n",
        "             'life_enjoyment', \n",
        "             'balanced_life', \n",
        "             'emotional_flex',\n",
        "             'health_categorical',\n",
        "             'total_health',\n",
        "             'genres'],\n",
        "            axis = 1),\n",
        "            data['self_actualization'], # y to be predicted\n",
        "            test_size=0.3,\n",
        "            random_state=0) \n",
        "\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "featurepipe = Pipeline([('scaler', FunctionTransformer()),\n",
        "                 ('reg', Lasso())])\n",
        "\n",
        "featurepipe.fit(X_train, y_train)\n",
        "predicted = featurepipe.predict(X_test)\n",
        "\n",
        "# print MSE\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_test, predicted))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1965349138581005\n"
          ]
        }
      ]
    }
  ]
}
